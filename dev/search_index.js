var documenterSearchIndex = {"docs":
[{"location":"howtos/howto_marker/#How-to-use-the-Marker-API","page":"Marker API","title":"How to use the Marker API","text":"","category":"section"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Below we showcase how to use LIKWID's marker API to monitor hardware performance counters for simple SAXPY operations (\"single precision a times x plus y\" for vectors x,y and scalar a) executed on CPU, multiple (CPU) threads, GPU, and CPU+GPU.","category":"page"},{"location":"howtos/howto_marker/#likwid-perfctr","page":"Marker API","title":"likwid-perfctr","text":"","category":"section"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"To use the marker API you need to run Julia under likwid-perctr (actually, that's not entirely true, see here for how to use the marker API dynamically from within a running Julia session). In particular, you need to use the -m option to activate the marker API, provide -c <cpuids> to state the cpu ids (starting at 0!) to monitor, and use -g <perfgrp> to specify the performance group that you want to measure. To list the performance groups that are available on your system (that is for your CPU model) you can either use PerfMon.supported_groups (or likwid-perfctr -a from the command-line).","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"For example, full commands could look like this:","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"likwid-perfctr -c 0 -g FLOPS_DP -m julia (monitoring double precision FLOPS on CPU 0)\nlikwid-perfctr -c 0-3 -g MEM -m julia (monitoring memory operations on CPUs 0 to 3)","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Important: It is absolutely crucial that you pin your Julia threads to the cpu threads that you passed to -c so that they are actually running on those cpu threads! While one could, in principle, use LIKWID's -C (capitalized) or likwid-pin with an appropriate mask for this we strongly recommend to use JULIA_EXCLUSIVE=1 for simple compact 0-N pinning or ThreadPinning.jl for more fine-grained control. For example, JULIA_EXCLUSIVE=1 likwid-perfctr -c 0-3 -g MEM -m julia -t 4.","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"(Part of the reason why we discourage using -C is that it only works when running Julia with only a single thread but leads to incorrect pinning for Threads.nthreads() > 1!)","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"For more information on likwid-perfctr, check out the official documentation.","category":"page"},{"location":"howtos/howto_marker/#likwid-perfctr-with-NVIDIA-GPUs","page":"Marker API","title":"likwid-perfctr with NVIDIA GPUs","text":"","category":"section"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Works the same way as for CPUs (see above) only that","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"-G <gpuids> takes the place of -c <cpuids> and\n-W <perfgrp> takes the place of -g <perfgrp>.","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"To list the performance groups that are available for your GPU you can either use NvMon.supported_groups (or likwid-perfctr -a from the command-line).","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Example call:","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"likwid-perfctr -G 0 -W FLOPS_SP -m julia would monitor single precision FLOPS on GPU 0","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"For more information, check out the NVIDIA GPU section of the LIKWID documention.","category":"page"},{"location":"howtos/howto_marker/#saxpy_cpu","page":"Marker API","title":"Example: CPU","text":"","category":"section"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Example that demonstrates using the CPU marker API.","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"# saxpy_cpu.jl\nusing LIKWID\nusing LinearAlgebra\n\nN = 100_000_000\na = 3.141f0\nz = zeros(Float32, N)\nx = rand(Float32, N)\ny = rand(Float32, N)\n\nfunction saxpy_cpu!(z,a,x,y)\n    z .= a .* x .+ y\nend\n\nMarker.init()\n\nsaxpy_cpu!(z,a,x,y) # warmup\n@marker \"saxpy_cpu\" saxpy_cpu!(z,a,x,y)\n\nMarker.close()","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Output of JULIA_EXCLUSIVE=1 likwid-perfctr -c 0 -g FLOPS_SP -m julia saxpy_cpu.jl:","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Warning: The Marker API requires the application to run on the selected CPUs.\nWarning: likwid-perfctr pins the application only when using the -C command line option.\nWarning: LIKWID assumes that the application does it before the first instrumented code region is started.\nWarning: You can use the string in the environment variable LIKWID_THREADS to pin you application to\nWarning: to the CPUs specified after the -c command line option.\n--------------------------------------------------------------------------------\nCPU name:\tIntel(R) Xeon(R) Gold 6148 CPU @ 2.40GHz\nCPU type:\tIntel Skylake SP processor\nCPU clock:\t2.39 GHz\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nRegion saxpy_cpu, Group 1: FLOPS_SP\n+-------------------+------------+\n|    Region Info    | HWThread 0 |\n+-------------------+------------+\n| RDTSC Runtime [s] |   0.097326 |\n|     call count    |          1 |\n+-------------------+------------+\n\n+------------------------------------------+---------+------------+\n|                   Event                  | Counter | HWThread 0 |\n+------------------------------------------+---------+------------+\n|             INSTR_RETIRED_ANY            |  FIXC0  |   10850760 |\n|           CPU_CLK_UNHALTED_CORE          |  FIXC1  |   69311210 |\n|           CPU_CLK_UNHALTED_REF           |  FIXC2  |          0 |\n| FP_ARITH_INST_RETIRED_128B_PACKED_SINGLE |   PMC0  |          0 |\n|    FP_ARITH_INST_RETIRED_SCALAR_SINGLE   |   PMC1  |        111 |\n| FP_ARITH_INST_RETIRED_256B_PACKED_SINGLE |   PMC2  |    4805495 |\n| FP_ARITH_INST_RETIRED_512B_PACKED_SINGLE |   PMC3  |          0 |\n+------------------------------------------+---------+------------+\n\n+----------------------+------------+\n|        Metric        | HWThread 0 |\n+----------------------+------------+\n|  Runtime (RDTSC) [s] |     0.0973 |\n| Runtime unhalted [s] |     0.0289 |\n|      Clock [MHz]     |     inf    |\n|          CPI         |     6.3877 |\n|     SP [MFLOP/s]     |   395.0039 |\n|   AVX SP [MFLOP/s]   |   395.0028 |\n|  AVX512 SP [MFLOP/s] |          0 |\n|   Packed [MUOPS/s]   |    49.3753 |\n|   Scalar [MUOPS/s]   |     0.0011 |\n|  Vectorization ratio |    99.9977 |\n+----------------------+------------+","category":"page"},{"location":"howtos/howto_marker/#saxpy_threads","page":"Marker API","title":"Example: Multithreading","text":"","category":"section"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"warning: Warning\nIt is absolutely crucial that you pin the Julia threads to the cores that you are monitoring with LIKWID. As described above, likwid-perfctr -C ... (i.e. the capital C option) does not work correctly with Julia! Instead you should use JULIA_EXCLUSIVE=1 or ThreadPinning.jl for more fine-grained control.","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"# saxpy_threads.jl\nusing LIKWID\nusing LinearAlgebra\nusing Base.Threads: nthreads, @threads\n\n# Julia threads must be pinned! Printing the thread affinity.\n@threads :static for tid in 1:nthreads()\n    core = LIKWID.get_processor_id()\n    println(\"Thread $tid, Core $core\")\nend\n\nN = 100_000_000\na = 3.141f0\nzs = [zeros(Float32, N) for _ in 1:nthreads()]\nx = rand(Float32, N)\ny = rand(Float32, N)\n\nfunction saxpy_cpu!(z, a, x, y)\n    z .= a .* x .+ y\nend\n\nfunction saxpy_threads(zs, a, x, y)\n    @threads :static for tid in 1:nthreads()\n        @marker \"saxpy_cpu!\" saxpy_cpu!(zs[tid], a, x, y)\n    end\nend\n\nMarker.init()\n\nsaxpy_cpu!(zs[1], a, x, y) # warmup saxpy_cpu\nsaxpy_threads(zs, a, x, y)\n\nMarker.close()","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Output for JULIA_EXCLUSIVE=1 likwid-perfctr -c 0-2 -g FLOPS_SP -m julia --project=. -t3 threads.jl:","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Warning: The Marker API requires the application to run on the selected CPUs.\nWarning: likwid-perfctr pins the application only when using the -C command line option.\nWarning: LIKWID assumes that the application does it before the first instrumented code region is started.\nWarning: You can use the string in the environment variable LIKWID_THREADS to pin you application to\nWarning: to the CPUs specified after the -c command line option.\n--------------------------------------------------------------------------------\nCPU name:\tIntel(R) Xeon(R) Gold 6246 CPU @ 3.30GHz\nCPU type:\tIntel Cascadelake SP processor\nCPU clock:\t3.30 GHz\n--------------------------------------------------------------------------------\nThread 2, Core 1\nThread 3, Core 2\nThread 1, Core 0\n--------------------------------------------------------------------------------\nRegion saxpy_cpu!, Group 1: FLOPS_SP\n+-------------------+------------+------------+------------+\n|    Region Info    | HWThread 0 | HWThread 1 | HWThread 2 |\n+-------------------+------------+------------+------------+\n| RDTSC Runtime [s] |   0.146394 |   0.199333 |   0.178488 |\n|     call count    |          1 |          1 |          1 |\n+-------------------+------------+------------+------------+\n+------------------------------------------+---------+------------+------------+------------+\n|                   Event                  | Counter | HWThread 0 | HWThread 1 | HWThread 2 |\n+------------------------------------------+---------+------------+------------+------------+\n|             INSTR_RETIRED_ANY            |  FIXC0  |   46977220 |   47074720 |   47030020 |\n|           CPU_CLK_UNHALTED_CORE          |  FIXC1  |  383841400 |  399093000 |  382726500 |\n|           CPU_CLK_UNHALTED_REF           |  FIXC2  |  343281800 |  403328100 |  386764600 |\n| FP_ARITH_INST_RETIRED_128B_PACKED_SINGLE |   PMC0  |          0 |          0 |          0 |\n|    FP_ARITH_INST_RETIRED_SCALAR_SINGLE   |   PMC1  |          0 |          0 |          0 |\n| FP_ARITH_INST_RETIRED_256B_PACKED_SINGLE |   PMC2  |   25000000 |   25000000 |   25000000 |\n| FP_ARITH_INST_RETIRED_512B_PACKED_SINGLE |   PMC3  |          0 |          0 |          0 |\n+------------------------------------------+---------+------------+------------+------------+\n+-----------------------------------------------+---------+------------+-----------+-----------+--------------+\n|                     Event                     | Counter |     Sum    |    Min    |    Max    |      Avg     |\n+-----------------------------------------------+---------+------------+-----------+-----------+--------------+\n|             INSTR_RETIRED_ANY STAT            |  FIXC0  |  141081960 |  46977220 |  47074720 |     47027320 |\n|           CPU_CLK_UNHALTED_CORE STAT          |  FIXC1  | 1165660900 | 382726500 | 399093000 | 3.885536e+08 |\n|           CPU_CLK_UNHALTED_REF STAT           |  FIXC2  | 1133374500 | 343281800 | 403328100 |    377791500 |\n| FP_ARITH_INST_RETIRED_128B_PACKED_SINGLE STAT |   PMC0  |          0 |         0 |         0 |            0 |\n|    FP_ARITH_INST_RETIRED_SCALAR_SINGLE STAT   |   PMC1  |          0 |         0 |         0 |            0 |\n| FP_ARITH_INST_RETIRED_256B_PACKED_SINGLE STAT |   PMC2  |   75000000 |  25000000 |  25000000 |     25000000 |\n| FP_ARITH_INST_RETIRED_512B_PACKED_SINGLE STAT |   PMC3  |          0 |         0 |         0 |            0 |\n+-----------------------------------------------+---------+------------+-----------+-----------+--------------+\n+----------------------+------------+------------+------------+\n|        Metric        | HWThread 0 | HWThread 1 | HWThread 2 |\n+----------------------+------------+------------+------------+\n|  Runtime (RDTSC) [s] |     0.1464 |     0.1993 |     0.1785 |\n| Runtime unhalted [s] |     0.1163 |     0.1209 |     0.1160 |\n|      Clock [MHz]     |  3689.9336 |  3265.3756 |  3265.5725 |\n|          CPI         |     8.1708 |     8.4779 |     8.1379 |\n|     SP [MFLOP/s]     |  1366.1725 |  1003.3472 |  1120.5229 |\n|   AVX SP [MFLOP/s]   |  1366.1725 |  1003.3472 |  1120.5229 |\n|  AVX512 SP [MFLOP/s] |          0 |          0 |          0 |\n|   Packed [MUOPS/s]   |   170.7716 |   125.4184 |   140.0654 |\n|   Scalar [MUOPS/s]   |          0 |          0 |          0 |\n|  Vectorization ratio |        100 |        100 |        100 |\n+----------------------+------------+------------+------------+\n+---------------------------+------------+-----------+-----------+-----------+\n|           Metric          |     Sum    |    Min    |    Max    |    Avg    |\n+---------------------------+------------+-----------+-----------+-----------+\n|  Runtime (RDTSC) [s] STAT |     0.5242 |    0.1464 |    0.1993 |    0.1747 |\n| Runtime unhalted [s] STAT |     0.3532 |    0.1160 |    0.1209 |    0.1177 |\n|      Clock [MHz] STAT     | 10220.8817 | 3265.3756 | 3689.9336 | 3406.9606 |\n|          CPI STAT         |    24.7866 |    8.1379 |    8.4779 |    8.2622 |\n|     SP [MFLOP/s] STAT     |  3490.0426 | 1003.3472 | 1366.1725 | 1163.3475 |\n|   AVX SP [MFLOP/s] STAT   |  3490.0426 | 1003.3472 | 1366.1725 | 1163.3475 |\n|  AVX512 SP [MFLOP/s] STAT |          0 |         0 |         0 |         0 |\n|   Packed [MUOPS/s] STAT   |   436.2554 |  125.4184 |  170.7716 |  145.4185 |\n|   Scalar [MUOPS/s] STAT   |          0 |         0 |         0 |         0 |\n|  Vectorization ratio STAT |        300 |       100 |       100 |       100 |\n+---------------------------+------------+-----------+-----------+-----------+","category":"page"},{"location":"howtos/howto_marker/#saxpy_gpu","page":"Marker API","title":"Example: GPU","text":"","category":"section"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Example that demonstrates how to use the GPU marker API:","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"# saxpy_gpu.jl\nusing LIKWID\nusing CUDA\n\n@assert CUDA.functional()\n\nN = 100_000_000\na = 3.141f0\nz_gpu = CUDA.zeros(Float32, N)\nx_gpu = CUDA.rand(Float32, N)\ny_gpu = CUDA.rand(Float32, N)\n\nfunction saxpy_gpu!(z,a,x,y)\n    CUDA.@sync z .= a .* x .+ y\nend\n\nGPUMarker.init()\n\nsaxpy_gpu!(z_gpu,a,x_gpu,y_gpu) # warmup\n@gpumarker \"saxpy_gpu\" saxpy_gpu!(z_gpu,a,x_gpu,y_gpu)\n\nGPUMarker.close()","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Output of likwid-perfctr -G 0 -W FLOPS_SP -m julia saxpy_gpu.jl:","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"--------------------------------------------------------------------------------\nCPU name:\tIntel(R) Xeon(R) Gold 6246 CPU @ 3.30GHz\nCPU type:\tIntel Cascadelake SP processor\nCPU clock:\t3.30 GHz\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nRegion saxpy_gpu, Group 1: FLOPS_SP\n+-------------------+----------+\n|    Region Info    |   GPU 0  |\n+-------------------+----------+\n| RDTSC Runtime [s] | 0.010824 |\n|     call count    |        1 |\n+-------------------+----------+\n+----------------------------------------------------+---------+-----------+\n|                        Event                       | Counter |   GPU 0   |\n+----------------------------------------------------+---------+-----------+\n| SMSP_SASS_THREAD_INST_EXECUTED_OP_FADD_PRED_ON_SUM |   GPU0  |         0 |\n| SMSP_SASS_THREAD_INST_EXECUTED_OP_FMUL_PRED_ON_SUM |   GPU1  |         0 |\n| SMSP_SASS_THREAD_INST_EXECUTED_OP_FFMA_PRED_ON_SUM |   GPU2  | 100000000 |\n+----------------------------------------------------+---------+-----------+\n+---------------------+------------+\n|        Metric       |    GPU 0   |\n+---------------------+------------+\n| Runtime (RDTSC) [s] |     0.0108 |\n|     SP [MFLOP/s]    | 18477.1502 |\n+---------------------+------------+","category":"page"},{"location":"howtos/howto_marker/#saxpy_cpugpu","page":"Marker API","title":"Example: CPU+GPU","text":"","category":"section"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Example that demonstrates how to use both the CPU and GPU marker API in one application.","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"# saxpy.jl\nusing LIKWID\nusing CUDA\n\n@assert CUDA.functional()\n\nN = 100_000_000\na = 3.141f0\nz = zeros(Float32, N)\nx = rand(Float32, N)\ny = rand(Float32, N)\n\nz_gpu = CUDA.zeros(Float32, N)\nx_gpu = CUDA.rand(Float32, N)\ny_gpu = CUDA.rand(Float32, N)\n\nfunction saxpy_cpu!(z,a,x,y)\n    z .= a .* x .+ y\nend\n\nfunction saxpy_gpu!(z,a,x,y)\n    CUDA.@sync z .= a .* x .+ y\nend\n\nMarker.init()\nGPUMarker.init()\n\nsaxpy_cpu!(z,a,x,y) # warmup\n@marker \"saxpy_cpu\" saxpy_cpu!(z,a,x,y)\n\nsaxpy_gpu!(z_gpu,a,x_gpu,y_gpu) # warmup\n@gpumarker \"saxpy_gpu\" saxpy_gpu!(z_gpu,a,x_gpu,y_gpu)\n\nMarker.close()\nGPUMarker.close()","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Output of JULIA_EXCLUSIVE=1 likwid-perfctr -c 0 -g FLOPS_SP -G 0 -W FLOPS_SP -m julia saxpy.jl:","category":"page"},{"location":"howtos/howto_marker/","page":"Marker API","title":"Marker API","text":"Warning: The Marker API requires the application to run on the selected CPUs.\nWarning: likwid-perfctr pins the application only when using the -C command line option.\nWarning: LIKWID assumes that the application does it before the first instrumented code region is started.\nWarning: You can use the string in the environment variable LIKWID_THREADS to pin you application to\nWarning: to the CPUs specified after the -c command line option.\n--------------------------------------------------------------------------------\nCPU name:\tIntel(R) Xeon(R) Gold 6246 CPU @ 3.30GHz\nCPU type:\tIntel Cascadelake SP processor\nCPU clock:\t3.30 GHz\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\n--------------------------------------------------------------------------------\nRegion saxpy_cpu, Group 1: FLOPS_SP\n+-------------------+------------+\n|    Region Info    | HWThread 0 |\n+-------------------+------------+\n| RDTSC Runtime [s] |   0.090796 |\n|     call count    |          1 |\n+-------------------+------------+\n+------------------------------------------+---------+------------+\n|                   Event                  | Counter | HWThread 0 |\n+------------------------------------------+---------+------------+\n|             INSTR_RETIRED_ANY            |  FIXC0  |   59866700 |\n|           CPU_CLK_UNHALTED_CORE          |  FIXC1  |  344927500 |\n|           CPU_CLK_UNHALTED_REF           |  FIXC2  |  298780700 |\n| FP_ARITH_INST_RETIRED_128B_PACKED_SINGLE |   PMC0  |          0 |\n|    FP_ARITH_INST_RETIRED_SCALAR_SINGLE   |   PMC1  |        111 |\n| FP_ARITH_INST_RETIRED_256B_PACKED_SINGLE |   PMC2  |   25000000 |\n| FP_ARITH_INST_RETIRED_512B_PACKED_SINGLE |   PMC3  |          0 |\n+------------------------------------------+---------+------------+\n+----------------------+------------+\n|        Metric        | HWThread 0 |\n+----------------------+------------+\n|  Runtime (RDTSC) [s] |     0.0908 |\n| Runtime unhalted [s] |     0.1045 |\n|      Clock [MHz]     |  3809.5859 |\n|          CPI         |     5.7616 |\n|     SP [MFLOP/s]     |  2202.7354 |\n|   AVX SP [MFLOP/s]   |  2202.7341 |\n|  AVX512 SP [MFLOP/s] |          0 |\n|   Packed [MUOPS/s]   |   275.3418 |\n|   Scalar [MUOPS/s]   |     0.0012 |\n|  Vectorization ratio |    99.9996 |\n+----------------------+------------+\nRegion saxpy_gpu, Group 1: FLOPS_SP\n+-------------------+----------+\n|    Region Info    |   GPU 0  |\n+-------------------+----------+\n| RDTSC Runtime [s] | 0.010824 |\n|     call count    |        1 |\n+-------------------+----------+\n+----------------------------------------------------+---------+-----------+\n|                        Event                       | Counter |   GPU 0   |\n+----------------------------------------------------+---------+-----------+\n| SMSP_SASS_THREAD_INST_EXECUTED_OP_FADD_PRED_ON_SUM |   GPU0  |         0 |\n| SMSP_SASS_THREAD_INST_EXECUTED_OP_FMUL_PRED_ON_SUM |   GPU1  |         0 |\n| SMSP_SASS_THREAD_INST_EXECUTED_OP_FFMA_PRED_ON_SUM |   GPU2  | 100000000 |\n+----------------------------------------------------+---------+-----------+\n+---------------------+------------+\n|        Metric       |    GPU 0   |\n+---------------------+------------+\n| Runtime (RDTSC) [s] |     0.0108 |\n|     SP [MFLOP/s]    | 18477.1502 |\n+---------------------+------------+","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"EditURL = \"https://github.com/JuliaPerf/LIKWID.jl/blob/main/docs/src/howtos/howto_pinning.jl\"","category":"page"},{"location":"howtos/howto_pinning/#How-to-pin-Julia-threads","page":"Pinning Julia Threads","title":"How to pin Julia threads","text":"","category":"section"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Below, we demonstrate how to use LIKWID.jl to pin Julia threads to specific cores. However, before we do that, let us note two things.","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"note: Note\nInstead of LIKWID's pinning features, we generally strongly recommend to use ThreadPinning.jl to pin Julia threads to cores, as it provides many more options and visualizations!","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"note: Note\nNote that Julia implements task-based multithreading where N tasks get mapped onto M OS threads (M:N hybrid threading). We will pin the Julia (p)threads and not the tasks. Depending on how the latter are started/configured, tasks may migrate between Julia threads!","category":"page"},{"location":"howtos/howto_pinning/#Dynamic-pinning","page":"Pinning Julia Threads","title":"Dynamic pinning","text":"","category":"section"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"First, make sure to start Julia in multithreaded mode, i.e. julia -t N where N is the desired number of Julia threads (below I'll use N=10).","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"N = Threads.nthreads()","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"10","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Let's find out on which cores the Julia threads are currently running (before we've pinned them). We will use LIKWID.get_processor_id in combination with Threads.@threads :static for, which guarantees that the tasks associated with different instances of the loop body get executed on different Julia threads (ThreadPinning.jl provides @tspawnat as a nice(r) alternative).","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"using LIKWID\ncoreids = zeros(Int, N)\nThreads.@threads :static for i in 1:N\n    coreids[i] = LIKWID.get_processor_id()\nend\nprintln(\"Cores: \", coreids)","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Cores: [37, 40, 38, 41, 39, 42, 32, 33, 47, 34]\n","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Since querying all core ids is a common operation, we provide LIKWID.get_processor_ids which returns all core ids right away.","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"println(\"Cores: \", LIKWID.get_processor_ids())","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Cores: [37, 40, 38, 41, 39, 42, 32, 33, 47, 34]\n","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"To pin a thread to a specific core, there is LIKWID.pinthread. Using Threads.@threads :static for like above, we can, for example, pin the N Julia threads to the first N cores.","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"cores_firstN = 0:N-1\nThreads.@threads :static for i in 1:N\n    LIKWID.pinthread(cores_firstN[i])\nend\nprintln(\"Cores: \", LIKWID.get_processor_ids())","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Cores: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"To avoid the explicit for-loop, we can directly use LIKWID.pinthreads to pin all Julia threads. Let's realize a less trivial shuffled mapping.","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"using Random\ncores_firstN_shuffeled = shuffle(cores_firstN)\nLIKWID.pinthreads(cores_firstN_shuffeled)\nprintln(\"Cores: \", LIKWID.get_processor_ids())\nLIKWID.get_processor_ids() == cores_firstN_shuffeled","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"true","category":"page"},{"location":"howtos/howto_pinning/#likwid-pin","page":"Pinning Julia Threads","title":"likwid-pin","text":"","category":"section"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Command-line interface tool for pinning (p)threads. For details, check out the official documentation.","category":"page"},{"location":"howtos/howto_pinning/#pin-mask","page":"Pinning Julia Threads","title":"Important: Mask","text":"","category":"section"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"(See this discussion on the Julia discourse.)","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"In general, likwid-pin pins all pthreads. However, julia involves more than the \"Julia user threads\" specified via the -t option. For example, it create an additional unix signal thread (in src/signals-unix.c) and - unless OPENBLAS_NUM_THREADS=1 - the OpenBLAS related threads (blas_thread_init () in [..]/lib/julia/libopenblas64_.so). Hence, when you run likwid-pin -c 0-3 julia -t 4 the four cores (0-3) are actually oversubscribed and multiple \"Julia user threads\" get pinned to the same core.","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"To work around this, we need to provide a mask to likwid-pin via the -s option. To compute an appropriate mask for N \"Julia user threads\" you may use the helper function LIKWID.pinmask(N):","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"LIKWID.pinmask(4)","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"\"0xffffffffffffffe1\"","category":"page"},{"location":"howtos/howto_pinning/#Example","page":"Pinning Julia Threads","title":"Example","text":"","category":"section"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"(See https://github.com/JuliaPerf/LIKWID.jl/tree/main/examples/cli/likwid-pin/.)","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"# pin.jl\nusing Base.Threads\n\nglibc_coreid() = @ccall sched_getcpu()::Cint\n\n@threads :static for i in 1:nthreads()\n    println(\"Thread: $(i), CPU: $(glibc_coreid())\")\nend","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"Running this file with e.g. likwid-pin -s 0xffffffffffffffe1 -c 1,3,5,7 julia -t 4 pin.jl one obtains","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"[pthread wrapper]\n[pthread wrapper] MAIN -> 1\n[pthread wrapper] PIN_MASK: 0->3  1->5  2->7\n[pthread wrapper] SKIP MASK: 0xFFFFFFFFFFFFFFE1\n\tthreadid 140576878921280 -> SKIP\n\tthreadid 140576612378176 -> hwthread 3 - OK\n\tthreadid 140576590759488 -> hwthread 5 - OK\n\tthreadid 140576494188096 -> hwthread 7 - OK\nThread: 1, CPU: 1\nThread: 2, CPU: 3\nThread: 3, CPU: 5\nThread: 4, CPU: 7","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"If you're wondering about the -s 0xffffffffffffffe1 option, see Mask above.","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"","category":"page"},{"location":"howtos/howto_pinning/","page":"Pinning Julia Threads","title":"Pinning Julia Threads","text":"This page was generated using Literate.jl.","category":"page"},{"location":"references/topo_gpu/#GPU-Topology","page":"GPU topology","title":"GPU Topology","text":"","category":"section"},{"location":"references/topo_gpu/#Index","page":"GPU topology","title":"Index","text":"","category":"section"},{"location":"references/topo_gpu/","page":"GPU topology","title":"GPU topology","text":"Pages   = [\"topo_gpu.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"references/topo_gpu/#Functions","page":"GPU topology","title":"Functions","text":"","category":"section"},{"location":"references/topo_gpu/","page":"GPU topology","title":"GPU topology","text":"LIKWID.init_topology_gpu()\nLIKWID.finalize_topology_gpu()\nLIKWID.get_gpu_topology()","category":"page"},{"location":"references/topo_gpu/#LIKWID.init_topology_gpu-Tuple{}","page":"GPU topology","title":"LIKWID.init_topology_gpu","text":"Initialize LIKWIDs GPU topology module.\n\n\n\n\n\n","category":"method"},{"location":"references/topo_gpu/#LIKWID.finalize_topology_gpu-Tuple{}","page":"GPU topology","title":"LIKWID.finalize_topology_gpu","text":"Finalize LIKWIDs GPU topology module.\n\n\n\n\n\n","category":"method"},{"location":"references/topo_gpu/#LIKWID.get_gpu_topology-Tuple{}","page":"GPU topology","title":"LIKWID.get_gpu_topology","text":"Get GPU topology\n\n\n\n\n\n","category":"method"},{"location":"references/topo_gpu/#Types","page":"GPU topology","title":"Types","text":"","category":"section"},{"location":"references/topo_gpu/","page":"GPU topology","title":"GPU topology","text":"LIKWID.GpuTopology\nLIKWID.GpuDevice","category":"page"},{"location":"references/topo_gpu/#LIKWID.GpuTopology","page":"GPU topology","title":"LIKWID.GpuTopology","text":"Topology information of GPUs\n\n\n\n\n\n","category":"type"},{"location":"references/topo_gpu/#LIKWID.GpuDevice","page":"GPU topology","title":"LIKWID.GpuDevice","text":"Detailed information about a GPU device\n\n\n\n\n\n","category":"type"},{"location":"references/power/","page":"Power / Energy","title":"Power / Energy","text":"using LIKWID","category":"page"},{"location":"references/power/#Power-/-Energy","page":"Power / Energy","title":"Power / Energy","text":"","category":"section"},{"location":"references/power/#Example","page":"Power / Energy","title":"Example","text":"","category":"section"},{"location":"references/power/","page":"Power / Energy","title":"Power / Energy","text":"General power information:","category":"page"},{"location":"references/power/","page":"Power / Energy","title":"Power / Energy","text":"julia> power = LIKWID.Power.get_power_info()\nLIKWID.PowerInfo\n├ baseFrequency: 3300.0 MHz\n├ minFrequency: 1200.0 MHz\n├ turbo: TurboBoost()\n├ hasRAPL: true\n├ powerUnit: 125000.0\n├ timeUnit: 976.0\n├ uncoreMinFreq: 1200.0 MHz\n├ uncoreMaxFreq: 2400.0 MHz\n├ perfBias: 6\n└ domains: ... (5 elements)\n\njulia> power.domains\n(PowerDomain(PKG, ...), PowerDomain(PP0, ...), PowerDomain(PP1, ...), PowerDomain(DRAM, ...), PowerDomain(PLATFORM, ...))\n\njulia> first(power.domains)\nLIKWID.PowerDomain\n├ id: 0\n├ type: PKG\n├ supportFlags: 27\n├ energyUnit: 6.103515625e-5\n├ tdp: 1.65e8\n├ minPower: 6.8e7\n├ maxPower: 1.65e8\n├ maxTimeWindow: 31232.0\n├ supportInfo: true\n├ supportStatus: true\n├ supportPerf: true\n├ supportPolicy: false\n└ supportLimit: true","category":"page"},{"location":"references/power/","page":"Power / Energy","title":"Power / Energy","text":"Energy measurement:","category":"page"},{"location":"references/power/","page":"Power / Energy","title":"Power / Energy","text":"julia> LIKWID.Power.measure(; cpuid=0, domainid=0) do\n        sleep(1)\n       end\n29.9920654296875 μJ\n\njulia> LIKWID.Power.measure(; cpuid=0, domainid=0) do\n        sum(sin(rand()) for _ in 1:1_000_000)\n       end\n0.5574951171875 μJ","category":"page"},{"location":"references/power/","page":"Power / Energy","title":"Power / Energy","text":"(Note that the example requires that the first (perhaps only) Julia thread is pinned to the CPU thread with id 0.)","category":"page"},{"location":"references/power/#Index","page":"Power / Energy","title":"Index","text":"","category":"section"},{"location":"references/power/","page":"Power / Energy","title":"Power / Energy","text":"Pages   = [\"power.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"references/power/#Functions","page":"Power / Energy","title":"Functions","text":"","category":"section"},{"location":"references/power/","page":"Power / Energy","title":"Power / Energy","text":"LIKWID.Power.init\nLIKWID.Power.finalize\nLIKWID.Power.get_power_info\nLIKWID.Power.start_power\nLIKWID.Power.stop_power\nLIKWID.Power.get_power\nLIKWID.Power.measure","category":"page"},{"location":"references/power/#LIKWID.Power.init","page":"Power / Energy","title":"LIKWID.Power.init","text":"Initialize power measurements for the given CPU. Returns the RAPL status, i.e. false (no RAPL) or true (RAPL working).\n\n\n\n\n\n","category":"function"},{"location":"references/power/#LIKWID.Power.finalize","page":"Power / Energy","title":"LIKWID.Power.finalize","text":"Finalize power measurements.\n\n\n\n\n\n","category":"function"},{"location":"references/power/#LIKWID.Power.get_power_info","page":"Power / Energy","title":"LIKWID.Power.get_power_info","text":"get_power_info() -> LIKWID.PowerInfo\n\nGet power / energy information.\n\n\n\n\n\n","category":"function"},{"location":"references/power/#LIKWID.Power.start_power","page":"Power / Energy","title":"LIKWID.Power.start_power","text":"Return the start value for a cpu (cpuid) for the domain with domainid.\n\n\n\n\n\n","category":"function"},{"location":"references/power/#LIKWID.Power.stop_power","page":"Power / Energy","title":"LIKWID.Power.stop_power","text":"Return the stop value for a cpu (cpuid) for the domain with domainid.\n\n\n\n\n\n","category":"function"},{"location":"references/power/#LIKWID.Power.get_power","page":"Power / Energy","title":"LIKWID.Power.get_power","text":"get_power(p_start::Integer, p_stop::Integer, domainid::Integer)\n\nCalculate the μJ from the values retrieved by start_power() and stop_power().\n\n\n\n\n\n","category":"function"},{"location":"references/power/#LIKWID.Power.measure","page":"Power / Energy","title":"LIKWID.Power.measure","text":"measure(f; cpuid::Integer=0, domainid::Integer)\n\nMeasure / calculate the energy for the given cpuid and domainid over the execution of the function f using Power.start_power, Power.stop_power, etc. under the hood. Automatically initializes and finalizes the power module.\n\nExamples\n\njulia> LIKWID.Power.measure(; cpuid=0, domainid=0) do\n           sleep(1)\n       end\n15.13702392578125 μJ\n\n\n\n\n\n","category":"function"},{"location":"references/power/#Types","page":"Power / Energy","title":"Types","text":"","category":"section"},{"location":"references/power/","page":"Power / Energy","title":"Power / Energy","text":"LIKWID.PowerInfo\nLIKWID.PowerDomain\nLIKWID.LibLikwid.PowerType\nLIKWID.TurboBoost","category":"page"},{"location":"references/power/#LIKWID.PowerInfo","page":"Power / Energy","title":"LIKWID.PowerInfo","text":"Power information\n\n\n\n\n\n","category":"type"},{"location":"references/power/#LIKWID.PowerDomain","page":"Power / Energy","title":"LIKWID.PowerDomain","text":"Power domain information\n\n\n\n\n\n","category":"type"},{"location":"references/power/#LIKWID.LibLikwid.PowerType","page":"Power / Energy","title":"LIKWID.LibLikwid.PowerType","text":"Different types of power domains\n\n\n\n\n\n","category":"type"},{"location":"references/power/#LIKWID.TurboBoost","page":"Power / Energy","title":"LIKWID.TurboBoost","text":"Turbo boost information\n\n\n\n\n\n","category":"type"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"EditURL = \"https://github.com/JuliaPerf/LIKWID.jl/blob/main/docs/src/howtos/howto_marker_dynamic.jl\"","category":"page"},{"location":"howtos/howto_marker_dynamic/#howto_marker_dynamic","page":"Marker API: Dynamic Usage","title":"Marker API (CPU): Dynamic Usage","text":"","category":"section"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"warning: Warning\nThe dynamic marker API usage is currently still experimental.","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"This is a demo of how to use the marker API to monitor the performance of a computation (do_flops below) running on multiple Julia threads using LIKWID from within Julia (i.e. without using likwid-perfctr ...). You can simply start Julia with julia -t N.","category":"page"},{"location":"howtos/howto_marker_dynamic/#Measurement","page":"Marker API: Dynamic Usage","title":"Measurement","text":"","category":"section"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"We consider the following simple function designed to do trivial floating point computations.","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"function do_flops(a, b, c, num_flops)\n    for _ in 1:num_flops\n        c = a * b + c\n    end\n    return c\nend","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"do_flops (generic function with 1 method)","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"Let's run a computation and monitor the performance via the marker API, concretely @perfmon_marker and @marker.","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"using LIKWID\nusing Base.Threads: @threads, nthreads\n\n@perfmon_marker \"FLOPS_DP\" begin\n    NUM_FLOPS = 100_000_000\n    a = 1.8\n    b = 3.2\n    c = 1.0\n    @threads :static for tid in 1:nthreads()\n        @marker \"calc_flops\" c = do_flops(c, a, b, NUM_FLOPS)\n        sin(b) # not monitored\n        @marker \"exponential\" exp(a)\n    end\nend","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"\nRegion: calc_flops, Group: FLOPS_DP\n┌───────────────────────────┬───────────┬───────────┬───────────┐\n│                     Event │  Thread 1 │  Thread 2 │  Thread 3 │\n├───────────────────────────┼───────────┼───────────┼───────────┤\n│          ACTUAL_CPU_CLOCK │   3.213e8 │ 3.21238e8 │ 3.21314e8 │\n│             MAX_CPU_CLOCK │ 2.23315e8 │ 2.23278e8 │ 2.23329e8 │\n│      RETIRED_INSTRUCTIONS │ 3.02219e8 │ 3.23243e8 │ 3.02222e8 │\n│       CPU_CLOCKS_UNHALTED │ 3.20743e8 │ 3.19392e8 │ 3.20809e8 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │     1.0e8 │     1.0e8 │     1.0e8 │\n│                     MERGE │       0.0 │       0.0 │       0.0 │\n└───────────────────────────┴───────────┴───────────┴───────────┘\n┌──────────────────────┬───────────┬───────────┬───────────┐\n│               Metric │  Thread 1 │  Thread 2 │  Thread 3 │\n├──────────────────────┼───────────┼───────────┼───────────┤\n│  Runtime (RDTSC) [s] │ 0.0911222 │ 0.0911035 │ 0.0911281 │\n│ Runtime unhalted [s] │  0.131151 │  0.131126 │  0.131156 │\n│          Clock [MHz] │   3524.78 │   3524.68 │   3524.71 │\n│                  CPI │   1.06129 │  0.988086 │    1.0615 │\n│         DP [MFLOP/s] │   1097.43 │   1097.66 │   1097.36 │\n└──────────────────────┴───────────┴───────────┴───────────┘\n\nRegion: exponential, Group: FLOPS_DP\n┌───────────────────────────┬──────────┬──────────┬──────────┐\n│                     Event │ Thread 1 │ Thread 2 │ Thread 3 │\n├───────────────────────────┼──────────┼──────────┼──────────┤\n│          ACTUAL_CPU_CLOCK │  90372.0 │  88095.0 │  88595.0 │\n│             MAX_CPU_CLOCK │  62254.0 │  60687.0 │  61519.0 │\n│      RETIRED_INSTRUCTIONS │   6264.0 │   6004.0 │   6377.0 │\n│       CPU_CLOCKS_UNHALTED │   7289.0 │   6338.0 │   8291.0 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │     27.0 │     27.0 │     27.0 │\n│                     MERGE │      0.0 │      0.0 │      0.0 │\n└───────────────────────────┴──────────┴──────────┴──────────┘\n┌──────────────────────┬────────────┬────────────┬────────────┐\n│               Metric │   Thread 1 │   Thread 2 │   Thread 3 │\n├──────────────────────┼────────────┼────────────┼────────────┤\n│  Runtime (RDTSC) [s] │ 9.02097e-8 │ 6.00037e-8 │ 2.49811e-7 │\n│ Runtime unhalted [s] │ 3.68888e-5 │ 3.59594e-5 │ 3.61635e-5 │\n│          Clock [MHz] │    3556.36 │    3556.27 │    3528.09 │\n│                  CPI │    1.16363 │    1.05563 │    1.30014 │\n│         DP [MFLOP/s] │    299.303 │    449.972 │    108.082 │\n└──────────────────────┴────────────┴────────────┴────────────┘\n","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"Multiple groups are supported as well.","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"@perfmon_marker [\"FLOPS_DP\", \"CPI\"] begin\n        @marker \"exponential\" exp(3.141)\nend","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"\nRegion: exponential, Group: FLOPS_DP\n┌───────────────────────────┬──────────┐\n│                     Event │ Thread 1 │\n├───────────────────────────┼──────────┤\n│          ACTUAL_CPU_CLOCK │  96922.0 │\n│             MAX_CPU_CLOCK │  66444.0 │\n│      RETIRED_INSTRUCTIONS │   5927.0 │\n│       CPU_CLOCKS_UNHALTED │   6822.0 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │     10.0 │\n│                     MERGE │      0.0 │\n└───────────────────────────┴──────────┘\n┌──────────────────────┬────────────┐\n│               Metric │   Thread 1 │\n├──────────────────────┼────────────┤\n│  Runtime (RDTSC) [s] │  3.0206e-8 │\n│ Runtime unhalted [s] │ 3.95624e-5 │\n│          Clock [MHz] │     3573.6 │\n│                  CPI │      1.151 │\n│         DP [MFLOP/s] │    331.061 │\n└──────────────────────┴────────────┘\n\nRegion: exponential, Group: CPI\n┌──────────────────────┬──────────┐\n│                Event │ Thread 1 │\n├──────────────────────┼──────────┤\n│     ACTUAL_CPU_CLOCK │  49747.0 │\n│        MAX_CPU_CLOCK │  34300.0 │\n│ RETIRED_INSTRUCTIONS │   5695.0 │\n│  CPU_CLOCKS_UNHALTED │   4607.0 │\n│         RETIRED_UOPS │   6598.0 │\n└──────────────────────┴──────────┘\n┌──────────────────────┬────────────┐\n│               Metric │   Thread 1 │\n├──────────────────────┼────────────┤\n│  Runtime (RDTSC) [s] │ 2.00012e-8 │\n│ Runtime unhalted [s] │ 1.88052e-6 │\n│          Clock [MHz] │    3553.14 │\n│                  CPI │   0.808955 │\n│  CPI (based on uops) │   0.698242 │\n│                  IPC │    1.23616 │\n└──────────────────────┴────────────┘\n","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"","category":"page"},{"location":"howtos/howto_marker_dynamic/","page":"Marker API: Dynamic Usage","title":"Marker API: Dynamic Usage","text":"This page was generated using Literate.jl.","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"EditURL = \"https://github.com/JuliaPerf/LIKWID.jl/blob/main/docs/src/tutorials/counting_flops.jl\"","category":"page"},{"location":"tutorials/counting_flops/#Counting-FLOPs","page":"Counting FLOPs","title":"Counting FLOPs","text":"","category":"section"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"Have you ever wondered how many floating point operations (FLOPs) a certain block of code, e.g. a Julia function, has actually triggered in a CPU core? With LIKWID.jl you can readily answer this question!","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"Let's consider a simple example: SAXPY. The abbreviation SAXPY stands for single-precision (Float32) a times x plus y, i.e. the computation","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"z = a cdot x + y","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"Of course, we can readily write this as a Julia function.","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"saxpy!(z, a, x, y) = z .= a .* x .+ y","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"saxpy! (generic function with 1 method)","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"Preparing some random input we can perform the saxpy! operation as per usual (we're suppressing the unimportant output below).","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"const N = 10_000\nconst a = 3.141\nconst x = rand(N)\nconst y = rand(N)\nconst z = zeros(N)\n\nsaxpy!(z, a, x, y);","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"Let's now use LIKWID to count the actually performed FLOPs for this computation! Concretely, we measure the FLOPS_DP performance group, in which \"DP\" stands for \"double precision\".","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"using LIKWID\nmetrics, events = @perfmon \"FLOPS_DP\" saxpy!(z, a, x, y);","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"\nGroup: FLOPS_DP\n┌──────────────────────────────────────────┬──────────┐\n│                                    Event │ Thread 1 │\n├──────────────────────────────────────────┼──────────┤\n│                        INSTR_RETIRED_ANY │  11761.0 │\n│                    CPU_CLK_UNHALTED_CORE │ 135189.0 │\n│                     CPU_CLK_UNHALTED_REF │  97920.0 │\n│ FP_ARITH_INST_RETIRED_128B_PACKED_DOUBLE │      0.0 │\n│      FP_ARITH_INST_RETIRED_SCALAR_DOUBLE │      0.0 │\n│ FP_ARITH_INST_RETIRED_256B_PACKED_DOUBLE │   5000.0 │\n│ FP_ARITH_INST_RETIRED_512B_PACKED_DOUBLE │      0.0 │\n└──────────────────────────────────────────┴──────────┘\n┌──────────────────────┬────────────┐\n│               Metric │   Thread 1 │\n├──────────────────────┼────────────┤\n│  Runtime (RDTSC) [s] │  8.6735e-5 │\n│ Runtime unhalted [s] │ 5.64666e-5 │\n│          Clock [MHz] │    3305.37 │\n│                  CPI │    11.4947 │\n│         DP [MFLOP/s] │    230.587 │\n│     AVX DP [MFLOP/s] │    230.587 │\n│  AVX512 DP [MFLOP/s] │        0.0 │\n│     Packed [MUOPS/s] │    57.6468 │\n│     Scalar [MUOPS/s] │        0.0 │\n│  Vectorization ratio │      100.0 │\n└──────────────────────┴────────────┘\n","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"That was easy. Let's see what we got. Among all those results, for computing the total number of FLOPs we care about the metrics \"DP [MFLOP/s]\", which gives the MFLOPs per second, and \"Runtime (RDTSC) [s]\", which indicates the total runtime. By multiplying the two we get the desired total number of FLOPs.","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"flops_per_second = first(metrics[\"FLOPS_DP\"])[\"DP [MFLOP/s]\"] * 1e6\nruntime = first(metrics[\"FLOPS_DP\"])[\"Runtime (RDTSC) [s]\"]\nNFLOPs_actual = round(Int, flops_per_second * runtime)","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"20000","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"Let's check whether this number makes sense. Our vectors are of length N and for each element we perform two FLOPs in the SAXPY operation: one multiplication and one addition. Hence, our expectation is","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"NFLOPs_expected(N) = 2 * N\nNFLOPs_expected(N)","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"20000","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"Note that this perfectly matches our measurement result above!","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"NFLOPs_actual == NFLOPs_expected(N)","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"true","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"To rule out that this is just a big coincidence, let's try to modify N and check again. For convenience, let's wrap the above procedure into a function.","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"function count_FLOPs(N)\n    a = 3.141\n    x = rand(N)\n    y = rand(N)\n    z = zeros(N)\n    metrics, _ = perfmon(() -> saxpy!(z, a, x, y), \"FLOPS_DP\"; print=false)\n    flops_per_second = first(metrics[\"FLOPS_DP\"])[\"DP [MFLOP/s]\"] * 1e6\n    runtime = first(metrics[\"FLOPS_DP\"])[\"Runtime (RDTSC) [s]\"]\n    return round(Int, flops_per_second * runtime)\nend","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"count_FLOPs (generic function with 1 method)","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"See how it still matches our expectation when varying the input!","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"count_FLOPs(2 * N) == NFLOPs_expected(2 * N)","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"true","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"Feel free to play around further and apply this knowledge to other operations! As an inspiration: How many FLOPs does an exp.(x) or sin.(x) trigger? Does the answer depend on the length of x?","category":"page"},{"location":"tutorials/counting_flops/#Bonus:-Reactive-FLOPs-Counting","page":"Counting FLOPs","title":"Bonus: Reactive FLOPs Counting","text":"","category":"section"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"It is a lot of fun to combine the low-level performance monitoring tools of LIKWID.jl with the beautiful high-level interface provided by Pluto.jl. In the following example, we can arbitrarily modify the function computation and - through Pluto's reactivity - the counted number of FLOPs will automatically update.","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"(Image: counting_flops_reactive)","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"","category":"page"},{"location":"tutorials/counting_flops/","page":"Counting FLOPs","title":"Counting FLOPs","text":"This page was generated using Literate.jl.","category":"page"},{"location":"references/affinity/","page":"Affinity","title":"Affinity","text":"using LIKWID","category":"page"},{"location":"references/affinity/#Affinity","page":"Affinity","title":"Affinity","text":"","category":"section"},{"location":"references/affinity/#Example","page":"Affinity","title":"Example","text":"","category":"section"},{"location":"references/affinity/","page":"Affinity","title":"Affinity","text":"Query affinity domain information:","category":"page"},{"location":"references/affinity/","page":"Affinity","title":"Affinity","text":"julia> aff = LIKWID.get_affinity()\nLIKWID.AffinityDomains\n├ numberOfSocketDomains: 2\n├ numberOfNumaDomains: 2\n├ numberOfProcessorsPerSocket: 24\n├ numberOfCacheDomains: 2\n├ numberOfCoresPerCache: 12\n├ numberOfProcessorsPerCache: 24\n├ numberOfAffinityDomains: 9\n└ domains: ... (9 elements)\n\njulia> aff.domains\n9-element Vector{LIKWID.AffinityDomain}:\n LIKWID.AffinityDomain(\"N\", 48, 24, [0, 24, 1, 25, 2, 26, 3, 27, 4, 28  …  19, 43, 20, 44, 21, 45, 22, 46, 23, 47])\n LIKWID.AffinityDomain(\"S0\", 24, 12, [0, 24, 1, 25, 2, 26, 3, 27, 4, 28  …  7, 31, 8, 32, 9, 33, 10, 34, 11, 35])\n LIKWID.AffinityDomain(\"S1\", 24, 12, [12, 36, 13, 37, 14, 38, 15, 39, 16, 40  …  19, 43, 20, 44, 21, 45, 22, 46, 23, 47])\n LIKWID.AffinityDomain(\"D0\", 24, 12, [0, 24, 1, 25, 2, 26, 3, 27, 4, 28  …  7, 31, 8, 32, 9, 33, 10, 34, 11, 35])\n LIKWID.AffinityDomain(\"D1\", 24, 12, [12, 36, 13, 37, 14, 38, 15, 39, 16, 40  …  19, 43, 20, 44, 21, 45, 22, 46, 23, 47])\n LIKWID.AffinityDomain(\"C0\", 24, 12, [0, 24, 1, 25, 2, 26, 3, 27, 4, 28  …  7, 31, 8, 32, 9, 33, 10, 34, 11, 35])\n LIKWID.AffinityDomain(\"C1\", 24, 12, [12, 36, 13, 37, 14, 38, 15, 39, 16, 40  …  19, 43, 20, 44, 21, 45, 22, 46, 23, 47])\n LIKWID.AffinityDomain(\"M0\", 24, 12, [0, 24, 1, 25, 2, 26, 3, 27, 4, 28  …  7, 31, 8, 32, 9, 33, 10, 34, 11, 35])\n LIKWID.AffinityDomain(\"M1\", 24, 12, [12, 36, 13, 37, 14, 38, 15, 39, 16, 40  …  19, 43, 20, 44, 21, 45, 22, 46, 23, 47])","category":"page"},{"location":"references/affinity/#Index","page":"Affinity","title":"Index","text":"","category":"section"},{"location":"references/affinity/","page":"Affinity","title":"Affinity","text":"Pages   = [\"affinity.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"references/affinity/#Functions","page":"Affinity","title":"Functions","text":"","category":"section"},{"location":"references/affinity/","page":"Affinity","title":"Affinity","text":"LIKWID.init_affinity\nLIKWID.finalize_affinity\nLIKWID.get_affinity\nLIKWID.cpustr_to_cpulist\nLIKWID.get_processor_id\nLIKWID.get_processor_ids\nLIKWID.get_processor_id_glibc\nLIKWID.pinprocess\nLIKWID.pinthread\nLIKWID.pinthreads","category":"page"},{"location":"references/affinity/#LIKWID.init_affinity","page":"Affinity","title":"LIKWID.init_affinity","text":"Initialize LIKWIDs affinity domain module.\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#LIKWID.finalize_affinity","page":"Affinity","title":"LIKWID.finalize_affinity","text":"Close and finalize LIKWIDs affinity domain module.\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#LIKWID.get_affinity","page":"Affinity","title":"LIKWID.get_affinity","text":"Query affinity domain information\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#LIKWID.cpustr_to_cpulist","page":"Affinity","title":"LIKWID.cpustr_to_cpulist","text":"Transform a valid cpu string in LIKWID syntax into a list of CPU IDs\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#LIKWID.get_processor_id","page":"Affinity","title":"LIKWID.get_processor_id","text":"Returns the ID of the currently executing CPU.\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#LIKWID.get_processor_ids","page":"Affinity","title":"LIKWID.get_processor_ids","text":"Get the CPU core IDs of the Julia threads.\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#LIKWID.get_processor_id_glibc","page":"Affinity","title":"LIKWID.get_processor_id_glibc","text":"Returns the ID of the currently executing CPU via glibcs sched_getcpu function.\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#LIKWID.pinprocess","page":"Affinity","title":"LIKWID.pinprocess","text":"Pins the current process to the CPU given as cpuid.\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#LIKWID.pinthread","page":"Affinity","title":"LIKWID.pinthread","text":"Pins the current thread to the CPU given as cpuid.\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#LIKWID.pinthreads","page":"Affinity","title":"LIKWID.pinthreads","text":"Pin all Julia threads to the CPU cores coreids. Note that length(coreids) == Threads.nthreads() must hold!\n\n\n\n\n\n","category":"function"},{"location":"references/affinity/#Types","page":"Affinity","title":"Types","text":"","category":"section"},{"location":"references/affinity/","page":"Affinity","title":"Affinity","text":"LIKWID.AffinityDomains\nLIKWID.AffinityDomain","category":"page"},{"location":"references/affinity/#LIKWID.AffinityDomains","page":"Affinity","title":"LIKWID.AffinityDomains","text":"Information about the affinity domains\n\n\n\n\n\n","category":"type"},{"location":"references/affinity/#LIKWID.AffinityDomain","page":"Affinity","title":"LIKWID.AffinityDomain","text":"An affinity domain\n\n\n\n\n\n","category":"type"},{"location":"references/perfmon/#Performance-Monitoring-(PerfMon)","page":"Performance monitoring","title":"Performance Monitoring (PerfMon)","text":"","category":"section"},{"location":"references/perfmon/#API","page":"Performance monitoring","title":"API","text":"","category":"section"},{"location":"references/perfmon/","page":"Performance monitoring","title":"Performance monitoring","text":"Pages   = [\"perfmon.md\"]\nOrder   = [:function, :macro, :type]","category":"page"},{"location":"references/perfmon/#Functions","page":"Performance monitoring","title":"Functions","text":"","category":"section"},{"location":"references/perfmon/","page":"Performance monitoring","title":"Performance monitoring","text":"Modules = [LIKWID.PerfMon]","category":"page"},{"location":"references/perfmon/#LIKWID.PerfMon.add_event_set-Tuple{AbstractString}","page":"Performance monitoring","title":"LIKWID.PerfMon.add_event_set","text":"add_event_set(estr) -> groupid\n\nAdd a performance group or a custom event set to the perfmon module. Returns a groupid (starting at 1) which is required to later specify the event set.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_event_results-Tuple{Any, Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_event_results","text":"get_event_results([groupid_or_groupname, eventid_or_eventname, threadid::Integer])\n\nRetrieve the results of monitored events. Same as get_metric_results but for raw events.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_id_of_active_group-Tuple{}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_id_of_active_group","text":"Return the groupid of the currently activate group.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_id_of_event-Tuple{Any, AbstractString}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_id_of_event","text":"Get the id of the event with the given name.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_id_of_group-Tuple{AbstractString}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_id_of_group","text":"Get the id of the group with the given name.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_id_of_metric-Tuple{Any, AbstractString}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_id_of_metric","text":"Get the id of the metric with the given name.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_last_metric-Tuple{Integer, Integer, Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_last_metric","text":"Return the derived metric result of the last measurement cycle identified by group groupid and the indices for metric metricidx and thread threadidx (all starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_last_result-Tuple{Integer, Integer, Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_last_result","text":"Return the raw counter register result of the last measurement cycle identified by group groupid and the indices for event eventidx and thread threadidx (all starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_longinfo_of_group-Tuple{Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_longinfo_of_group","text":"Return the (long) description of a performance group with id groupid (starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_metric-Tuple{Integer, Integer, Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_metric","text":"Return the derived metric result of all measurements identified by group groupid and the indices for metric metricidx and thread threadidx (all starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_metric_results-Tuple{Any, Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_metric_results","text":"get_metric_results([groupid_or_groupname, metricid_or_metricname, threadid::Integer])\n\nRetrieve the results of monitored metrics.\n\nOptionally, a group, metric, and threadid can be provided to select a subset of metrics or a single metric. If given as integers, note that groupid, metricid, and threadid all start at 1 and the latter enumerates the monitored cpu threads.\n\nIf no arguments are provided, a nested data structure is returned in which different levels correspond to performance groups, cpu threads, and metrics (in this order).\n\nExamples\n\njulia> PerfMon.get_metric_results(\"FLOPS_DP\")\n4-element Vector{OrderedDict{String, Float64}}:\n OrderedDict(\"Runtime (RDTSC) [s]\" => 1.1381168037989857, \"Runtime unhalted [s]\" => 0.0016642799007831007, \"Clock [MHz]\" => 2911.9285695819794, \"CPI\" => NaN, \"DP [MFLOP/s]\" => 0.0)\n OrderedDict(\"Runtime (RDTSC) [s]\" => 1.1381168037989857, \"Runtime unhalted [s]\" => 1.4755564705029072, \"Clock [MHz]\" => 3523.1114993407705, \"CPI\" => 0.3950777002592585, \"DP [MFLOP/s]\" => 17608.069202657578)\n OrderedDict(\"Runtime (RDTSC) [s]\" => 1.1381168037989857, \"Runtime unhalted [s]\" => 7.80437228993214e-5, \"Clock [MHz]\" => 2638.6244625814124, \"CPI\" => NaN, \"DP [MFLOP/s]\" => 0.0)\n OrderedDict(\"Runtime (RDTSC) [s]\" => 1.1381168037989857, \"Runtime unhalted [s]\" => 7.050705084934875e-5, \"Clock [MHz]\" => 2807.7525945849698, \"CPI\" => NaN, \"DP [MFLOP/s]\" => 0.0)\n\njulia> PerfMon.get_metric_results(\"FLOPS_DP\", 2) # results of second monitored cpu thread\nOrderedDict{String, Float64} with 5 entries:\n  \"Runtime (RDTSC) [s]\"  => 1.13812\n  \"Runtime unhalted [s]\" => 1.47556\n  \"Clock [MHz]\"          => 3523.11\n  \"CPI\"                  => 0.395078\n  \"DP [MFLOP/s]\"         => 17608.1\n\njulia> PerfMon.get_metric_results(\"FLOPS_DP\", \"DP [MFLOP/s]\", 2)\n17608.069202657578\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_metric_results-Tuple{}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_metric_results","text":"get_metric_results()\n\nGet the metric results for all performance groups and all monitored (PerfMon.init) cpu threads.\n\nReturns a an OrderedDict whose keys correspond to the performance groups and the values hold the results for all monitored cpu threads.\n\nExamples\n\njulia> results = PerfMon.get_metric_results()\nOrderedDict{String, Vector{OrderedDict{String, Float64}}} with 1 entry:\n  \"FLOPS_DP\" => [OrderedDict(\"Runtime (RDTSC) [s]\"=>1.13812, \"Runtime unhalted [s]\"=>0.00166428, \"Clock [MHz]\"=>291…\n\njulia> PerfMon.get_metric_results()[\"FLOPS_DP\"][2][\"DP [MFLOP/s]\"]\n17608.069202657578\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_name_of_counter-Tuple{Integer, Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_name_of_counter","text":"Return the name of the counter register identified by groupid and eventidx (both starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_name_of_event-Tuple{Integer, Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_name_of_event","text":"Return the name of the event identified by groupid and eventidx (both starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_name_of_group-Tuple{Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_name_of_group","text":"Return the name of the group identified by groupid (starts at 1). If it is a custom event set, the name is set to Custom.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_name_of_metric-Tuple{Integer, Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_name_of_metric","text":"Return the name of a derived metric identified by groupid and metricidx (both starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_number_of_events-Tuple{Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_number_of_events","text":"Return the amount of events in the given group with id groupid (starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_number_of_groups-Tuple{}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_number_of_groups","text":"Return the number of groups currently registered in the perfmon module.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_number_of_metrics-Tuple{Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_number_of_metrics","text":"Return the amount of metrics in the given group with id groupid (starts at 1). Always zero for custom event sets.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_number_of_threads-Tuple{}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_number_of_threads","text":"Return the number of threads initialized in the perfmon module.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_result-Tuple{Integer, Integer, Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_result","text":"Return the raw counter register result of all measurements identified by group groupid and the indices for event eventidx and thread threadidx (all starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_shortinfo_of_group-Tuple{Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_shortinfo_of_group","text":"Return the short information about a performance group with id groupid (starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.get_time_of_group-Tuple{Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.get_time_of_group","text":"Return the measurement time for group identified by groupid (starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.init","page":"Performance monitoring","title":"LIKWID.PerfMon.init","text":"init(cpuid_or_cpuids)\n\nInitialize LIKWID's PerfMon module for the cpu threads with the given ids (starting at 0!).\n\n\n\n\n\n","category":"function"},{"location":"references/perfmon/#LIKWID.PerfMon.isgroupsupported-Tuple{Any}","page":"Performance monitoring","title":"LIKWID.PerfMon.isgroupsupported","text":"Checks if the given performance group is available on the current system.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.list_events-Tuple{Any}","page":"Performance monitoring","title":"LIKWID.PerfMon.list_events","text":"List all the events of a given group (groupid starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.list_metrics-Tuple{Any}","page":"Performance monitoring","title":"LIKWID.PerfMon.list_metrics","text":"List all the metrics of a given group (groupid starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.perfmon-Tuple{Any, Any}","page":"Performance monitoring","title":"LIKWID.PerfMon.perfmon","text":"perfmon(f, group_or_groups[; cpuids, autopin=true]) -> metrics, events\n\nMonitor performance groups while executing the given function f on one or multiple Julia threads. Note that\n\nPerfMon.init and PerfMon.finalize are called automatically\nthe measurement of multiple performance groups is sequential and requires multiple executions of f!\n\nThe returned data structures metrics and events are nested and different levels correspond to performance groups, threads, and measured metrics (in this order).\n\nKeyword arguments:\n\ncpuids (default: currently used CPU threads): specify the CPU threads (~ cores) to be monitored\nautopin (default: true): automatically pin Julia threads to the CPU threads (~ cores) they are currently running on (to avoid migration and wrong results).\nprint (default: true): toggle printing of result tables\nfinalize (default: true): call PerfMon.finalize in the end\n\nExample\n\njulia> using LIKWID\n\njulia> x = rand(1000); y = rand(1000);\n\njulia> metrics, events = perfmon(\"FLOPS_DP\") do\n           x .+ y;\n       end;\n\nGroup: FLOPS_DP\n┌───────────────────────────┬───────────┐\n│                     Event │  Thread 1 │\n├───────────────────────────┼───────────┤\n│          ACTUAL_CPU_CLOCK │ 2.32582e8 │\n│             MAX_CPU_CLOCK │ 1.61685e8 │\n│      RETIRED_INSTRUCTIONS │ 3.12775e8 │\n│       CPU_CLOCKS_UNHALTED │ 2.29064e8 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │    4964.0 │\n│                     MERGE │       0.0 │\n└───────────────────────────┴───────────┘\n┌──────────────────────┬───────────┐\n│               Metric │  Thread 1 │\n├──────────────────────┼───────────┤\n│  Runtime (RDTSC) [s] │ 0.0659737 │\n│ Runtime unhalted [s] │ 0.0949394 │\n│          Clock [MHz] │   3524.02 │\n│                  CPI │  0.732361 │\n│         DP [MFLOP/s] │ 0.0752421 │\n└──────────────────────┴───────────┘\n\njulia> first(metrics[\"FLOPS_DP\"]) # all metrics of the first Julia thread\nOrderedDict{String, Float64} with 5 entries:\n  \"Runtime (RDTSC) [s]\"  => 0.0659737\n  \"Runtime unhalted [s]\" => 0.0949394\n  \"Clock [MHz]\"          => 3524.02\n  \"CPI\"                  => 0.732361\n  \"DP [MFLOP/s]\"         => 0.0752421\n\njulia> first(events[\"FLOPS_DP\"]) # all raw events of the first Julia thread\nOrderedDict{String, Float64} with 6 entries:\n  \"ACTUAL_CPU_CLOCK\"          => 2.32582e8\n  \"MAX_CPU_CLOCK\"             => 1.61685e8\n  \"RETIRED_INSTRUCTIONS\"      => 3.12775e8\n  \"CPU_CLOCKS_UNHALTED\"       => 2.29064e8\n  \"RETIRED_SSE_AVX_FLOPS_ALL\" => 4964.0\n  \"MERGE\"                     => 0.0\n\njulia> metrics, events = perfmon((\"FLOPS_DP\", \"MEM1\")) do\n           x .+ y;\n       end;\n\nGroup: FLOPS_DP\n┌───────────────────────────┬──────────┐\n│                     Event │ Thread 1 │\n├───────────────────────────┼──────────┤\n│          ACTUAL_CPU_CLOCK │  85773.0 │\n│             MAX_CPU_CLOCK │  60074.0 │\n│      RETIRED_INSTRUCTIONS │   6605.0 │\n│       CPU_CLOCKS_UNHALTED │  32291.0 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │   1000.0 │\n│                     MERGE │      0.0 │\n└───────────────────────────┴──────────┘\n┌──────────────────────┬────────────┐\n│               Metric │   Thread 1 │\n├──────────────────────┼────────────┤\n│  Runtime (RDTSC) [s] │ 9.99103e-6 │\n│ Runtime unhalted [s] │ 3.50123e-5 │\n│          Clock [MHz] │    3497.79 │\n│                  CPI │    4.88887 │\n│         DP [MFLOP/s] │     100.09 │\n└──────────────────────┴────────────┘\n\nGroup: MEM1\n┌──────────────────────┬──────────┐\n│                Event │ Thread 1 │\n├──────────────────────┼──────────┤\n│     ACTUAL_CPU_CLOCK │ 185118.0 │\n│        MAX_CPU_CLOCK │ 129042.0 │\n│ RETIRED_INSTRUCTIONS │   6213.0 │\n│  CPU_CLOCKS_UNHALTED │  15122.0 │\n│       DRAM_CHANNEL_0 │    148.0 │\n│       DRAM_CHANNEL_1 │    110.0 │\n│       DRAM_CHANNEL_2 │    319.0 │\n│       DRAM_CHANNEL_3 │    326.0 │\n└──────────────────────┴──────────┘\n┌────────────────────────────────────────────┬────────────┐\n│                                     Metric │   Thread 1 │\n├────────────────────────────────────────────┼────────────┤\n│                        Runtime (RDTSC) [s] │ 6.53034e-6 │\n│                       Runtime unhalted [s] │ 7.55646e-5 │\n│                                Clock [MHz] │    3514.37 │\n│                                        CPI │    2.43393 │\n│ Memory bandwidth (channels 0-3) [MBytes/s] │    8849.77 │\n│ Memory data volume (channels 0-3) [GBytes] │  5.7792e-5 │\n└────────────────────────────────────────────┴────────────┘\n\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.read_counters-Tuple{}","page":"Performance monitoring","title":"LIKWID.PerfMon.read_counters","text":"Read the counter registers. To be executed after start_counters and before stop_counters. Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.setup_counters-Tuple{Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.setup_counters","text":"Program the counter registers to measure all events in group groupid (starts at 1). Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.start_counters-Tuple{}","page":"Performance monitoring","title":"LIKWID.PerfMon.start_counters","text":"Start the counter registers. Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.stop_counters-Tuple{}","page":"Performance monitoring","title":"LIKWID.PerfMon.stop_counters","text":"Stop the counter registers. Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.supported_groups-Tuple{}","page":"Performance monitoring","title":"LIKWID.PerfMon.supported_groups","text":"Return a dictionary of all available perfmon groups.\n\nExamples\n\njulia> PerfMon.supported_groups()\nDict{String, LIKWID.GroupInfoCompact} with 18 entries:\n  \"L2CACHE\"  => L2CACHE => L2 cache miss rate/ratio (experimental)\n  \"MEM2\"     => MEM2 => Main memory bandwidth in MBytes/s (channels 4-7)\n  \"NUMA\"     => NUMA => L2 cache bandwidth in MBytes/s (experimental)\n  \"BRANCH\"   => BRANCH => Branch prediction miss rate/ratio\n  \"FLOPS_SP\" => FLOPS_SP => Single Precision MFLOP/s\n  \"DIVIDE\"   => DIVIDE => Divide unit information\n  \"CPI\"      => CPI => Cycles per instruction\n  \"L2\"       => L2 => L2 cache bandwidth in MBytes/s (experimental)\n  \"L3\"       => L3 => L3 cache bandwidth in MBytes/s\n  \"L3CACHE\"  => L3CACHE => L3 cache miss rate/ratio (experimental)\n  \"CACHE\"    => CACHE => Data cache miss rate/ratio\n  \"ICACHE\"   => ICACHE => Instruction cache miss rate/ratio\n  \"TLB\"      => TLB => TLB miss rate/ratio\n  \"CLOCK\"    => CLOCK => Cycles per instruction\n  \"FLOPS_DP\" => FLOPS_DP => Double Precision MFLOP/s\n  \"ENERGY\"   => ENERGY => Power and Energy consumption\n  \"MEM1\"     => MEM1 => Main memory bandwidth in MBytes/s (channels 0-3)\n  \"DATA\"     => DATA => Load to store ratio\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.switch_group-Tuple{Integer}","page":"Performance monitoring","title":"LIKWID.PerfMon.switch_group","text":"Switch currently active group to groupid (starts with 1). Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/perfmon/#LIKWID.PerfMon.@perfmon-Tuple{Any, Any}","page":"Performance monitoring","title":"LIKWID.PerfMon.@perfmon","text":"@perfmon group_or_groups codeblock\n\nSee also: perfmon\n\nExample\n\njulia> using LIKWID\n\njulia> x = rand(1000); y = rand(1000);\n\njulia> metrics, events = @perfmon \"FLOPS_DP\" x .+ y;\n\nGroup: FLOPS_DP\n┌───────────────────────────┬──────────┐\n│                     Event │ Thread 1 │\n├───────────────────────────┼──────────┤\n│          ACTUAL_CPU_CLOCK │  88187.0 │\n│             MAX_CPU_CLOCK │  61789.0 │\n│      RETIRED_INSTRUCTIONS │   6705.0 │\n│       CPU_CLOCKS_UNHALTED │  34181.0 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │   1000.0 │\n│                     MERGE │      0.0 │\n└───────────────────────────┴──────────┘\n┌──────────────────────┬────────────┐\n│               Metric │   Thread 1 │\n├──────────────────────┼────────────┤\n│  Runtime (RDTSC) [s] │ 1.08307e-5 │\n│ Runtime unhalted [s] │ 3.59977e-5 │\n│          Clock [MHz] │    3496.42 │\n│                  CPI │    5.09784 │\n│         DP [MFLOP/s] │    92.3302 │\n└──────────────────────┴────────────┘\n\njulia> first(metrics[\"FLOPS_DP\"]) # all metrics of the first Julia thread\nOrderedDict{String, Float64} with 5 entries:\n  \"Runtime (RDTSC) [s]\"  => 8.56091e-6\n  \"Runtime unhalted [s]\" => 3.22377e-5\n  \"Clock [MHz]\"          => 3506.47\n  \"CPI\"                  => 4.78484\n  \"DP [MFLOP/s]\"         => 116.81\n\njulia> first(events[\"FLOPS_DP\"]) # all events of the first Julia thread\nOrderedDict{String, Float64} with 6 entries:\n  \"ACTUAL_CPU_CLOCK\"          => 78974.0\n  \"MAX_CPU_CLOCK\"             => 55174.0\n  \"RETIRED_INSTRUCTIONS\"      => 5977.0\n  \"CPU_CLOCKS_UNHALTED\"       => 28599.0\n  \"RETIRED_SSE_AVX_FLOPS_ALL\" => 1000.0\n  \"MERGE\"                     => 0.0\n\n\n\n\n\n","category":"macro"},{"location":"references/perfmon/#Types","page":"Performance monitoring","title":"Types","text":"","category":"section"},{"location":"references/perfmon/","page":"Performance monitoring","title":"Performance monitoring","text":"LIKWID.GroupInfoCompact","category":"page"},{"location":"references/perfmon/#LIKWID.GroupInfoCompact","page":"Performance monitoring","title":"LIKWID.GroupInfoCompact","text":"Essential information about a performance group\n\n\n\n\n\n","category":"type"},{"location":"references/access/#HPM-/-Access","page":"HPM / Access","title":"HPM / Access","text":"","category":"section"},{"location":"references/access/#Index","page":"HPM / Access","title":"Index","text":"","category":"section"},{"location":"references/access/","page":"HPM / Access","title":"HPM / Access","text":"Pages   = [\"access.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"references/access/#Functions","page":"HPM / Access","title":"Functions","text":"","category":"section"},{"location":"references/access/","page":"HPM / Access","title":"HPM / Access","text":"Modules = [LIKWID.HPM]","category":"page"},{"location":"references/access/#LIKWID.HPM.add_thread-Tuple{Any}","page":"HPM / Access","title":"LIKWID.HPM.add_thread","text":"Add the given CPU to the access module. This opens the commnunication to either the MSR/PCI files or the access daemon.\n\n\n\n\n\n","category":"method"},{"location":"references/access/#LIKWID.HPM.finalize-Tuple{}","page":"HPM / Access","title":"LIKWID.HPM.finalize","text":"Close the connections to the MSR/PCI files or the access daemon.\n\n\n\n\n\n","category":"method"},{"location":"references/access/#LIKWID.HPM.init-Tuple{}","page":"HPM / Access","title":"LIKWID.HPM.init","text":"Initialize the access module internals to either the MSR/PCI files or the access daemon\n\n\n\n\n\n","category":"method"},{"location":"references/access/#LIKWID.HPM.mode-Tuple{Union{LIKWID.LibLikwid.AccessMode, Integer}}","page":"HPM / Access","title":"LIKWID.HPM.mode","text":"Sets the mode how the MSR and PCI registers should be accessed. Available options:\n\n0 or LibLikwid.ACCESSMODE_DIRECT: direct access (propably root priviledges required)\n1 or LibLikwid.ACCESSMODE_DAEMON: accesses through the access daemon\n\nMust be called before HPM.init.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#Marker-API-(CPU)","page":"Marker API (CPU)","title":"Marker API (CPU)","text":"","category":"section"},{"location":"references/marker/#Example","page":"Marker API (CPU)","title":"Example","text":"","category":"section"},{"location":"references/marker/","page":"Marker API (CPU)","title":"Marker API (CPU)","text":"(See https://github.com/JuliaPerf/LIKWID.jl/tree/main/examples/perfctr.)","category":"page"},{"location":"references/marker/","page":"Marker API (CPU)","title":"Marker API (CPU)","text":"# perfctr.jl\nusing LIKWID\nusing LinearAlgebra\n\nMarker.init()\n\nA = rand(128, 64)\nB = rand(64, 128)\nC = zeros(128, 128)\n\n@marker for _ in 1:100\n    mul!(C, A, B)\nend\n\nMarker.close()","category":"page"},{"location":"references/marker/#Manual","page":"Marker API (CPU)","title":"Manual","text":"","category":"section"},{"location":"references/marker/","page":"Marker API (CPU)","title":"Marker API (CPU)","text":"# perfctr.jl\nusing LIKWID\nusing LinearAlgebra\n\nMarker.init()\n\nA = rand(128, 64)\nB = rand(64, 128)\nC = zeros(128, 128)\n\nMarker.registerregion(\"matmul\") # optional\nMarker.startregion(\"matmul\")\nfor _ in 1:100\n    mul!(C, A, B)\nend\nMarker.stopregion(\"matmul\")\n\nMarker.close()","category":"page"},{"location":"references/marker/#Index","page":"Marker API (CPU)","title":"Index","text":"","category":"section"},{"location":"references/marker/","page":"Marker API (CPU)","title":"Marker API (CPU)","text":"Pages   = [\"marker.md\"]\nOrder   = [:function, :macro, :type]","category":"page"},{"location":"references/marker/#API","page":"Marker API (CPU)","title":"API","text":"","category":"section"},{"location":"references/marker/","page":"Marker API (CPU)","title":"Marker API (CPU)","text":"Modules = [Marker]","category":"page"},{"location":"references/marker/#LIKWID.Marker.close-Tuple{}","page":"Marker API (CPU)","title":"LIKWID.Marker.close","text":"Close the connection to the LIKWID Marker API and write out measurement data to file. This file will be evaluated by likwid-perfctr.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.getregion-Tuple{AbstractString}","page":"Marker API (CPU)","title":"LIKWID.Marker.getregion","text":"getregion(regiontag::AbstractString, [num_events]) -> nevents, events, time, count\n\nGet the intermediate results of the region identified by regiontag. On success, it returns     * nevents: the number of events in the current group,     * events: a list with all the aggregated event results,     * time: the measurement time for the region and     * count: the number of calls.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.init-Tuple{}","page":"Marker API (CPU)","title":"LIKWID.Marker.init","text":"Initialize the Marker API, assuming that julia is running under likwid-perfctr. Must be called previous to all other functions.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.init_dynamic-Tuple{Any}","page":"Marker API (CPU)","title":"LIKWID.Marker.init_dynamic","text":"init_dynamic(group_or_groups; kwargs...)\n\nInitialize the full Marker API from within the current Julia session (i.e. no likwird-perfctr necessary). A performance group, e.g. \"FLOPS_DP\", must be provided as the first argument.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.init_nothreads-Tuple{}","page":"Marker API (CPU)","title":"LIKWID.Marker.init_nothreads","text":"Initialize the Marker API only on the main thread (assuming that julia is running under likwid-perfctr). LIKWID.Marker.threadinit() must be called manually.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.isactive-Tuple{}","page":"Marker API (CPU)","title":"LIKWID.Marker.isactive","text":"Checks whether the Marker API is active (by checking if the LIKWID_MODE environment variable has been set).\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.marker-Tuple{Any, AbstractString}","page":"Marker API (CPU)","title":"LIKWID.Marker.marker","text":"marker(f, regiontag::AbstractString)\n\nAdds a LIKWID marker region around the execution of the given function f using Marker.startregion, Marker.stopregion under the hood. Note that LIKWID.Marker.init() and LIKWID.Marker.close() must be called before and after, respectively.\n\nExamples\n\njulia> using LIKWID\n\njulia> Marker.init()\n\njulia> marker(\"sleeping...\") do\n           sleep(1)\n       end\ntrue\n\njulia> marker(()->rand(100), \"create rand vec\")\ntrue\n\njulia> Marker.close()\n\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.nextgroup-Tuple{}","page":"Marker API (CPU)","title":"LIKWID.Marker.nextgroup","text":"Switch to the next event set in a round-robin fashion. If you have set only one event set on the command line, this function performs no operation.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.perfmon_marker-Tuple{Any, Any}","page":"Marker API (CPU)","title":"LIKWID.Marker.perfmon_marker","text":"perfmon_marker(f, group_or_groups[; kwargs...])\n\nMonitor performance groups in marked areas (see @marker) while executing the given function f on one or multiple Julia threads.\n\nThis is an experimental feature!\n\nNote that\n\nMarker.init_dynamic, Marker.init, Marker.close, and PerfMon.finalize are called automatically\nthe measurement of multiple performance groups is sequential and requires multiple executions of f!\n\nKeyword arguments:\n\ncpuids (default: currently used CPU threads): specify the CPU threads (~ cores) to be monitored\nautopin (default: true): automatically pin Julia threads to the CPU threads (~ cores) they are currently running on (to avoid migration and wrong results).\nkeep (default: false): keep the temporarily created marker file\n\nExample\n\njulia> using LIKWID\n\njulia> perfmon_marker(\"FLOPS_DP\") do\n           # only the marked regions are monitored!\n           NUM_FLOPS = 100_000_000\n           a = 1.8\n           b = 3.2\n           c = 1.3\n           @marker \"calc_flops\" for _ in 1:NUM_FLOPS\n                c = a * b + c\n            end\n           z = a*b+c\n           @marker \"exponential\" exp(z)\n           sin(c)\n       end\n\nRegion: calc_flops, Group: FLOPS_DP\n┌───────────────────────────┬───────────┐\n│                     Event │  Thread 1 │\n├───────────────────────────┼───────────┤\n│          ACTUAL_CPU_CLOCK │ 3.00577e8 │\n│             MAX_CPU_CLOCK │ 2.08917e8 │\n│      RETIRED_INSTRUCTIONS │ 3.00005e8 │\n│       CPU_CLOCKS_UNHALTED │ 3.00067e8 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │     1.0e8 │\n│                     MERGE │       0.0 │\n└───────────────────────────┴───────────┘\n┌──────────────────────┬───────────┐\n│               Metric │  Thread 1 │\n├──────────────────────┼───────────┤\n│  Runtime (RDTSC) [s] │ 0.0852431 │\n│ Runtime unhalted [s] │  0.122687 │\n│          Clock [MHz] │   3524.84 │\n│                  CPI │   1.00021 │\n│         DP [MFLOP/s] │   1173.12 │\n└──────────────────────┴───────────┘\n\nRegion: exponential, Group: FLOPS_DP\n┌───────────────────────────┬──────────┐\n│                     Event │ Thread 1 │\n├───────────────────────────┼──────────┤\n│          ACTUAL_CPU_CLOCK │  85696.0 │\n│             MAX_CPU_CLOCK │  59192.0 │\n│      RETIRED_INSTRUCTIONS │   5072.0 │\n│       CPU_CLOCKS_UNHALTED │   6013.0 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │     27.0 │\n│                     MERGE │      0.0 │\n└───────────────────────────┴──────────┘\n┌──────────────────────┬────────────┐\n│               Metric │   Thread 1 │\n├──────────────────────┼────────────┤\n│  Runtime (RDTSC) [s] │ 2.60005e-7 │\n│ Runtime unhalted [s] │ 3.49786e-5 │\n│          Clock [MHz] │    3546.95 │\n│                  CPI │    1.18553 │\n│         DP [MFLOP/s] │    103.844 │\n└──────────────────────┴────────────┘\n\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.registerregion-Tuple{AbstractString}","page":"Marker API (CPU)","title":"LIKWID.Marker.registerregion","text":"Register a region with name regiontag to the Marker API. On success, true is returned.\n\nThis is an optional function to reduce the overhead of region registration at Marker.startregion. If you don't call registerregion, the registration is done at startregion.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.resetregion-Tuple{AbstractString}","page":"Marker API (CPU)","title":"LIKWID.Marker.resetregion","text":"Reset the values stored using the region name regiontag. On success, true is returned.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.startregion-Tuple{AbstractString}","page":"Marker API (CPU)","title":"LIKWID.Marker.startregion","text":"Start measurements under the name regiontag. On success, true is returned.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.stopregion-Tuple{AbstractString}","page":"Marker API (CPU)","title":"LIKWID.Marker.stopregion","text":"Stop measurements under the name regiontag. On success, true is returned.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.threadinit-Tuple{}","page":"Marker API (CPU)","title":"LIKWID.Marker.threadinit","text":"Add the current thread to the Marker API.\n\n\n\n\n\n","category":"method"},{"location":"references/marker/#LIKWID.Marker.@marker-Tuple{Any, Any}","page":"Marker API (CPU)","title":"LIKWID.Marker.@marker","text":"Convenience macro for flanking code with Marker.startregion and Marker.stopregion.\n\nExamples\n\njulia> using LIKWID\n\njulia> Marker.init()\n\njulia> @marker \"sleeping...\" sleep(1)\ntrue\n\njulia> @marker \"create rand vec\" rand(100)\ntrue\n\njulia> Marker.close()\n\n\n\n\n\n\n","category":"macro"},{"location":"references/marker/#LIKWID.Marker.@parallelmarker-Tuple{Any, Any}","page":"Marker API (CPU)","title":"LIKWID.Marker.@parallelmarker","text":"Convenience macro for flanking code with Marker.startregion and Marker.stopregion on all threads separately.\n\nExamples\n\njulia> using LIKWID\n\njulia> Marker.init()\n\njulia> @parallelmarker begin\n           Threads.@thread :static for i in 1:Threads.nthreads()\n               # thread-local computation\n           end\n       end\n\njulia> Marker.close()\n\n\n\n\n\n\n","category":"macro"},{"location":"references/marker/#LIKWID.Marker.@perfmon_marker-Tuple{Any, Any}","page":"Marker API (CPU)","title":"LIKWID.Marker.@perfmon_marker","text":"@perfmon_marker group_or_groups codeblock\n\nThis is an experimental feature!\n\nSee also: perfmon_marker\n\nExample\n\njulia> using LIKWID\n\njulia> @perfmon_marker \"FLOPS_DP\" begin\n           @marker \"exponential\" exp(3.141)\n       end\n\nRegion: exponential, Group: FLOPS_DP\n┌───────────────────────────┬──────────┐\n│                     Event │ Thread 1 │\n├───────────────────────────┼──────────┤\n│          ACTUAL_CPU_CLOCK │ 115146.0 │\n│             MAX_CPU_CLOCK │  78547.0 │\n│      RETIRED_INSTRUCTIONS │   4208.0 │\n│       CPU_CLOCKS_UNHALTED │   7112.0 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │     10.0 │\n│                     MERGE │      0.0 │\n└───────────────────────────┴──────────┘\n┌──────────────────────┬────────────┐\n│               Metric │   Thread 1 │\n├──────────────────────┼────────────┤\n│  Runtime (RDTSC) [s] │ 3.02056e-8 │\n│ Runtime unhalted [s] │ 4.70008e-5 │\n│          Clock [MHz] │     3591.4 │\n│                  CPI │    1.69011 │\n│         DP [MFLOP/s] │    331.064 │\n└──────────────────────┴────────────┘\n\n\n\n\n\n\n","category":"macro"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"EditURL = \"https://github.com/JuliaPerf/LIKWID.jl/blob/main/docs/src/howtos/howto_perfmon.jl\"","category":"page"},{"location":"howtos/howto_perfmon/#Performance-Monitoring","page":"Performance Monitoring","title":"Performance Monitoring","text":"","category":"section"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"Below we describe how one can use LIKWID.jl to measure the performance of a piece of Julia code on a hardware level.","category":"page"},{"location":"howtos/howto_perfmon/#CPU","page":"Performance Monitoring","title":"CPU","text":"","category":"section"},{"location":"howtos/howto_perfmon/#perfmon_macro","page":"Performance Monitoring","title":"The @perfmon macro","text":"","category":"section"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"The macro @perfmon is the easiest tool to use for performance monitoring. You need to provide two things:","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"the performance group(s) that you're interested in and\nthe piece of Julia code to be analyzed.","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"As for the first, you can use PerfMon.supported_groups to get a list of the performance groups available on your system. The most common ones, that should also be available on most systems, are FLOPSDP and FLOPSSP for obtaining information about double- and single-precision floating point operations.","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"As for point 2, pretty much every Julia code is syntactically valid, i.e. you can call a function or use, e.g., begin ... end to setup monitoring of a block of code. However, it is important to realize that, by default, @perfmon will only monitor the CPU threads (\"cores\") associated with Julia threads and, for example, does not realiably provide information about computations happening on separate BLAS threads. To monitor the latter, one can try to use the perfmon function instead.","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"using LIKWID\nusing Base.Threads\n\nN = 10_000\na = 3.141\nx = rand(N)\ny = rand(N)\nz = zeros(N)\n\nfunction saxpy!(z, a, x, y)\n    @threads :static for i in eachindex(z)\n        z[i] = a * x[i] + y[i]\n    end\n    return z\nend\nsaxpy!(z, a, x, y); # warmup\n\nmetrics, events = @perfmon \"FLOPS_DP\" saxpy!(z, a, x, y);","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"\nGroup: FLOPS_DP\n┌───────────────────────────┬──────────┬──────────┬──────────┐\n│                     Event │ Thread 1 │ Thread 2 │ Thread 3 │\n├───────────────────────────┼──────────┼──────────┼──────────┤\n│          ACTUAL_CPU_CLOCK │ 594353.0 │ 172690.0 │ 219724.0 │\n│             MAX_CPU_CLOCK │ 398790.0 │ 225764.0 │ 143752.0 │\n│      RETIRED_INSTRUCTIONS │  67624.0 │  80827.0 │  85597.0 │\n│       CPU_CLOCKS_UNHALTED │ 161793.0 │  63454.0 │  71502.0 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │   6668.0 │   6666.0 │   6666.0 │\n│                     MERGE │      0.0 │      0.0 │      0.0 │\n└───────────────────────────┴──────────┴──────────┴──────────┘\n┌──────────────────────┬─────────────┬────────────┬────────────┐\n│               Metric │    Thread 1 │   Thread 2 │   Thread 3 │\n├──────────────────────┼─────────────┼────────────┼────────────┤\n│  Runtime (RDTSC) [s] │  5.23601e-5 │ 5.23601e-5 │ 5.23601e-5 │\n│ Runtime unhalted [s] │ 0.000264663 │ 7.68981e-5 │ 9.78422e-5 │\n│          Clock [MHz] │     3346.97 │    1717.77 │    3432.53 │\n│                  CPI │     2.39254 │   0.785059 │   0.835333 │\n│         DP [MFLOP/s] │     127.349 │    127.311 │    127.311 │\n└──────────────────────┴─────────────┴────────────┴────────────┘\n","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"Apart from printing, the monitoring results are provided in form of the nested data structures metrics and events. For example, the FLOPS (floating point operations per second) can be queried as follows,","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"metrics[\"FLOPS_DP\"][1][\"DP [MFLOP/s]\"]","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"127.34884328126886","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"Here, \"FLOPS_DP is the performance group, 1 indicated the first Julia thread, and \"DP [MFLOP/s] is a LIKWID metric.","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"note: Note\nTo ensure a reliable monitoring process, @perfmon will automatically pin the Julia threads to the CPU threads they are currently running on (to avoid migration).","category":"page"},{"location":"howtos/howto_perfmon/#perfmon_function","page":"Performance Monitoring","title":"The perfmon function","text":"","category":"section"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"If you need more fine-grained control, you should use the perfmon function instead of the @perfmon macro. Among other things, it allows one to","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"disable automatic thread-pinning via autopin=false,\nmanually indicate the CPU threads (\"cores\") to be monitored through the cpuids keyword argument\nsuppress printing via print=false.","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"# since we'll have autopin=false, we must manually ensure that computations run on the\n# cpu threads / cores that we're monitoring!\nLIKWID.pinthreads([0,1,2])\nmetrics, events = perfmon(() -> saxpy!(z, a, x, y), \"FLOPS_DP\"; cpuids=[0,1], autopin=false);","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"\nGroup: FLOPS_DP\n┌───────────────────────────┬──────────┬──────────┐\n│                     Event │ Thread 1 │ Thread 2 │\n├───────────────────────────┼──────────┼──────────┤\n│          ACTUAL_CPU_CLOCK │ 805504.0 │ 677456.0 │\n│             MAX_CPU_CLOCK │ 548820.0 │ 451058.0 │\n│      RETIRED_INSTRUCTIONS │  64537.0 │ 103995.0 │\n│       CPU_CLOCKS_UNHALTED │ 181393.0 │ 120942.0 │\n│ RETIRED_SSE_AVX_FLOPS_ALL │   6668.0 │   6666.0 │\n│                     MERGE │      0.0 │      0.0 │\n└───────────────────────────┴──────────┴──────────┘\n┌──────────────────────┬─────────────┬─────────────┐\n│               Metric │    Thread 1 │    Thread 2 │\n├──────────────────────┼─────────────┼─────────────┤\n│  Runtime (RDTSC) [s] │ 0.000189612 │ 0.000189612 │\n│ Runtime unhalted [s] │ 0.000358688 │ 0.000301668 │\n│          Clock [MHz] │     3296.01 │     3372.87 │\n│                  CPI │     2.81068 │     1.16296 │\n│         DP [MFLOP/s] │     35.1665 │     35.1559 │\n└──────────────────────┴─────────────┴─────────────┘\n","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"Note that Julia's do syntax can often be useful here.","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"metrics, events = perfmon(\"FLOPS_DP\"; cpuids=[0,1], autopin=false, print=false) do\n    # code goes here...\n    saxpy!(z, a, x, y)\nend;","category":"page"},{"location":"howtos/howto_perfmon/#GPU","page":"Performance Monitoring","title":"GPU","text":"","category":"section"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"warning: Warning\nExperimental","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"using LIKWID\nusing CUDA\n\nN = 10_000\na = 3.141f0 # Float32\nx = CUDA.rand(Float32, N)\ny = CUDA.rand(Float32, N)\nz = CUDA.zeros(Float32, N)\n\nsaxpy!(z, a, x, y) = z .= a .* x .+ y\nsaxpy!(z, a, x, y); # warmup\n\nmetrics, events = @nvmon \"FLOPS_SP\" saxpy!(z, a, x, y);","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"\nGroup: FLOPS_SP\n┌────────────────────────────────────────────────────┬─────────┐\n│                                              Event │   GPU 1 │\n├────────────────────────────────────────────────────┼─────────┤\n│ SMSP_SASS_THREAD_INST_EXECUTED_OP_FADD_PRED_ON_SUM │     0.0 │\n│ SMSP_SASS_THREAD_INST_EXECUTED_OP_FMUL_PRED_ON_SUM │     0.0 │\n│ SMSP_SASS_THREAD_INST_EXECUTED_OP_FFMA_PRED_ON_SUM │ 10000.0 │\n└────────────────────────────────────────────────────┴─────────┘\n┌─────────────────────┬────────────┐\n│              Metric │      GPU 1 │\n├─────────────────────┼────────────┤\n│ Runtime (RDTSC) [s] │ 1.84467e10 │\n│        SP [MFLOP/s] │ 1.0842e-12 │\n└─────────────────────┴────────────┘\n","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"","category":"page"},{"location":"howtos/howto_perfmon/","page":"Performance Monitoring","title":"Performance Monitoring","text":"This page was generated using Literate.jl.","category":"page"},{"location":"references/timer/","page":"CPU clock timer","title":"CPU clock timer","text":"using LIKWID","category":"page"},{"location":"references/timer/#CPU-Clock-Timer","page":"CPU clock timer","title":"CPU Clock Timer","text":"","category":"section"},{"location":"references/timer/#Example","page":"CPU clock timer","title":"Example","text":"","category":"section"},{"location":"references/timer/","page":"CPU clock timer","title":"CPU clock timer","text":"Timing is as simple as","category":"page"},{"location":"references/timer/","page":"CPU clock timer","title":"CPU clock timer","text":"julia> LIKWID.Timer.@timeit sleep(1)\n(clock = 1.0021697811990014, cycles = 3307182468)","category":"page"},{"location":"references/timer/","page":"CPU clock timer","title":"CPU clock timer","text":"Apart from the time it took to execute sleep(1) (clock) one also gets the number of CPU clock cycles corresponding to the time interval (cycles).","category":"page"},{"location":"references/timer/","page":"CPU clock timer","title":"CPU clock timer","text":"Note that the macro usage above is essentially equivalent to the following manual sequence","category":"page"},{"location":"references/timer/","page":"CPU clock timer","title":"CPU clock timer","text":"julia> LIKWID.Timer.init()\ntrue\n\njulia> t_start = LIKWID.Timer.start_clock()\nTimerData(cycles start: 60459589412988386, cycles stop: 0)\n\njulia> sleep(1)\n\njulia> t_stop = LIKWID.Timer.stop_clock(t_start)\nTimerData(cycles start: 60459589412988386, cycles stop: 60459592861915014)\n\njulia> LIKWID.Timer.get_clock(t_stop)\n1.045121729122075\n\njulia> LIKWID.Timer.get_clock_cycles(t_stop)\n3448926580\n\njulia> LIKWID.Timer.finalize()","category":"page"},{"location":"references/timer/#Index","page":"CPU clock timer","title":"Index","text":"","category":"section"},{"location":"references/timer/","page":"CPU clock timer","title":"CPU clock timer","text":"Pages   = [\"timer.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"references/timer/#Functions","page":"CPU clock timer","title":"Functions","text":"","category":"section"},{"location":"references/timer/","page":"CPU clock timer","title":"CPU clock timer","text":"LIKWID.Timer.init\nLIKWID.Timer.finalize\nLIKWID.Timer.get_cpu_clock\nLIKWID.Timer.get_cpu_clock_current\nLIKWID.Timer.start_clock\nLIKWID.Timer.stop_clock\nLIKWID.Timer.get_clock\nLIKWID.Timer.get_clock_cycles\nLIKWID.Timer.timeit\nLIKWID.Timer.@timeit","category":"page"},{"location":"references/timer/#LIKWID.Timer.init","page":"CPU clock timer","title":"LIKWID.Timer.init","text":"Initialize LIKWIDs timer module\n\n\n\n\n\n","category":"function"},{"location":"references/timer/#LIKWID.Timer.finalize","page":"CPU clock timer","title":"LIKWID.Timer.finalize","text":"Close and finalize LIKWIDs timer module\n\n\n\n\n\n","category":"function"},{"location":"references/timer/#LIKWID.Timer.get_cpu_clock","page":"CPU clock timer","title":"LIKWID.Timer.get_cpu_clock","text":"Return the CPU clock determined at Timer.init().\n\n\n\n\n\n","category":"function"},{"location":"references/timer/#LIKWID.Timer.get_cpu_clock_current","page":"CPU clock timer","title":"LIKWID.Timer.get_cpu_clock_current","text":"Return the current CPU clock read from sysfs\n\n\n\n\n\n","category":"function"},{"location":"references/timer/#LIKWID.Timer.start_clock","page":"CPU clock timer","title":"LIKWID.Timer.start_clock","text":"Start the clock and return a LibLikwid.TimerData object including the start timestamp.\n\n\n\n\n\n","category":"function"},{"location":"references/timer/#LIKWID.Timer.stop_clock","page":"CPU clock timer","title":"LIKWID.Timer.stop_clock","text":"stop_clock(timer::LibLikwid.TimerData) -> newtimer::LibLikwid.TimerData\n\nStop the clock and return a LibLikwid.TimerData object including the start and stop timestamps. The input timer should be the output of Timer.start_clock().\n\n\n\n\n\n","category":"function"},{"location":"references/timer/#LIKWID.Timer.get_clock","page":"CPU clock timer","title":"LIKWID.Timer.get_clock","text":"get_clock(timer::LibLikwid.TimerData)\n\nReturn the measured interval in seconds for the given timer. The input timer should be the output of Timer.stop_clock.\n\n\n\n\n\n","category":"function"},{"location":"references/timer/#LIKWID.Timer.get_clock_cycles","page":"CPU clock timer","title":"LIKWID.Timer.get_clock_cycles","text":"get_clock_cycles(timer::LibLikwid.TimerData)\n\nReturn the measured interval in cycles for the given timer. The input timer should be the output of Timer.stop_clock.\n\n\n\n\n\n","category":"function"},{"location":"references/timer/#LIKWID.Timer.timeit","page":"CPU clock timer","title":"LIKWID.Timer.timeit","text":"timeit(f)\n\nTime the given function f using Timer.start_clock, Timer.stop_clock, etc. under the hood. Automatically initializes and finalizes the timer module.\n\nExamples\n\njulia> LIKWID.Timer.timeit() do\n           sleep(1)\n       end\n(clock = 1.0008815780376372, cycles = 3603224844)\n\n\n\n\n\n","category":"function"},{"location":"references/timer/#LIKWID.Timer.@timeit","page":"CPU clock timer","title":"LIKWID.Timer.@timeit","text":"Convenience macro for Timer.timeit.\n\nExamples\n\njulia> LIKWID.Timer.@timeit sleep(1)\n(clock = 1.0008815780376372, cycles = 3603224844)\n\n\n\n\n\n","category":"macro"},{"location":"references/topo/#CPU-/-NUMA-Topology","page":"CPU topology","title":"CPU / NUMA Topology","text":"","category":"section"},{"location":"references/topo/#Index","page":"CPU topology","title":"Index","text":"","category":"section"},{"location":"references/topo/","page":"CPU topology","title":"CPU topology","text":"Pages   = [\"topo.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"references/topo/#Functions","page":"CPU topology","title":"Functions","text":"","category":"section"},{"location":"references/topo/","page":"CPU topology","title":"CPU topology","text":"LIKWID.init_topology\nLIKWID.finalize_topology\nLIKWID.get_cpu_topology\nLIKWID.get_cpu_info\nLIKWID.print_supported_cpus\nLIKWID.init_numa\nLIKWID.finalize_numa\nLIKWID.get_numa_topology","category":"page"},{"location":"references/topo/#LIKWID.init_topology","page":"CPU topology","title":"LIKWID.init_topology","text":"Initialize LIKWIDs topology module.\n\n\n\n\n\n","category":"function"},{"location":"references/topo/#LIKWID.finalize_topology","page":"CPU topology","title":"LIKWID.finalize_topology","text":"Close and finalize LIKWIDs topology module.\n\n\n\n\n\n","category":"function"},{"location":"references/topo/#LIKWID.get_cpu_topology","page":"CPU topology","title":"LIKWID.get_cpu_topology","text":"get_cpu_topology() -> CpuTopology\n\nGet the CPU topology of the machine.\n\nAutomatically initializes the topology and NUMA modules, i.e. calls LIKWID.init_topology and LIKWID.init_numa.\n\n\n\n\n\n","category":"function"},{"location":"references/topo/#LIKWID.get_cpu_info","page":"CPU topology","title":"LIKWID.get_cpu_info","text":"get_cpu_info() -> CpuInfo\n\nGet detailed information about the CPU.\n\nAutomatically initializes the topology and NUMA modules, i.e. calls LIKWID.init_topology and LIKWID.init_numa.\n\n\n\n\n\n","category":"function"},{"location":"references/topo/#LIKWID.print_supported_cpus","page":"CPU topology","title":"LIKWID.print_supported_cpus","text":"print_supported_cpus(; cprint=true)\n\nPrint a list of all supported CPUs.\n\nIf cprint=false, LIKWID.jl will first capture the stdout and then print the list.\n\n\n\n\n\n","category":"function"},{"location":"references/topo/#LIKWID.init_numa","page":"CPU topology","title":"LIKWID.init_numa","text":"Initialize LIKWIDs NUMA module.\n\n\n\n\n\n","category":"function"},{"location":"references/topo/#LIKWID.finalize_numa","page":"CPU topology","title":"LIKWID.finalize_numa","text":"Close and finalize LIKWIDs NUMA module.\n\n\n\n\n\n","category":"function"},{"location":"references/topo/#LIKWID.get_numa_topology","page":"CPU topology","title":"LIKWID.get_numa_topology","text":"get_numa_topology() -> NumaTopology\n\nGet the NUMA topology of the machine.\n\nAutomatically initializes the topology, NUMA, and affinity modules, i.e. calls LIKWID.init_topology, LIKWID.init_numa, and LIKWID.init_affinity.\n\n\n\n\n\n","category":"function"},{"location":"references/topo/#Types","page":"CPU topology","title":"Types","text":"","category":"section"},{"location":"references/topo/","page":"CPU topology","title":"CPU topology","text":"LIKWID.CpuTopology\nLIKWID.CpuInfo\nLIKWID.HWThread\nLIKWID.CacheLevel\nLIKWID.NumaTopology\nLIKWID.NumaNode","category":"page"},{"location":"references/topo/#LIKWID.CpuTopology","page":"CPU topology","title":"LIKWID.CpuTopology","text":"CPU topology information\n\n\n\n\n\n","category":"type"},{"location":"references/topo/#LIKWID.CpuInfo","page":"CPU topology","title":"LIKWID.CpuInfo","text":"CPU information\n\n\n\n\n\n","category":"type"},{"location":"references/topo/#LIKWID.HWThread","page":"CPU topology","title":"LIKWID.HWThread","text":"Information about a hardware thread\n\n\n\n\n\n","category":"type"},{"location":"references/topo/#LIKWID.CacheLevel","page":"CPU topology","title":"LIKWID.CacheLevel","text":"Information about a cache level\n\n\n\n\n\n","category":"type"},{"location":"references/topo/#LIKWID.NumaTopology","page":"CPU topology","title":"LIKWID.NumaTopology","text":"CPU topology information\n\n\n\n\n\n","category":"type"},{"location":"references/topo/#LIKWID.NumaNode","page":"CPU topology","title":"LIKWID.NumaNode","text":"Information about a NUMA node\n\n\n\n\n\n","category":"type"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"EditURL = \"https://github.com/JuliaPerf/LIKWID.jl/blob/main/docs/src/howtos/howto_topology.jl\"","category":"page"},{"location":"howtos/howto_topology/#How-CPU-/-NUMA-Topology","page":"System Topology","title":"How  CPU / NUMA Topology","text":"","category":"section"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"The basis functionality of likwid-topology.","category":"page"},{"location":"howtos/howto_topology/#CPU","page":"System Topology","title":"CPU","text":"","category":"section"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"Query CPU topology information:","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"using LIKWID # hide\ntopo = LIKWID.get_cpu_topology()\ntopo.threadPool\ntopo.cacheLevels","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"3-element Vector{LIKWID.CacheLevel}:\n LIKWID.CacheLevel(1, :data, 8, 64, 64, 32768, 1, 0)\n LIKWID.CacheLevel(2, :unified, 16, 1024, 64, 1048576, 1, 0)\n LIKWID.CacheLevel(3, :unified, 11, 40960, 64, 28835840, 20, 0)","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"Get detailed CPU information:","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"cpuinfo = LIKWID.get_cpu_info()","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"LIKWID.CpuInfo\n├ family: 6\n├ model: 85\n├ stepping: 4\n├ vendor: 0\n├ part: 0\n├ clock: 0\n├ turbo: true\n├ osname: Intel(R) Xeon(R) Gold 6148F CPU @ 2.40GHz\n├ name: Intel Skylake SP processor\n├ short_name: skylakeX\n├ features: FP ACPI MMX SSE SSE2 HTT TM RDTSCP MONITOR VMX EIST TM2 SSSE FMA SSE4.1 SSE4.2 AES AVX RDRAND HLE AVX2 RTM AVX512 RDSEED SSE3 \n├ isIntel: true\n├ architecture: x86_64\n├ supportUncore: true\n├ supportClientmem: false\n├ featureFlags: 4328456191\n├ perf_version: 4\n├ perf_num_ctr: 8\n├ perf_width_ctr: 48\n└ perf_num_fixed_ctr: 3","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"Query information about NUMA nodes:","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"numa = LIKWID.get_numa_topology()","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"LIKWID.NumaTopology\n├ numberOfNodes: 2\n└ nodes: ... (2 elements)","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"numa_node = first(numa.nodes)","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"LIKWID.NumaNode\n├ id: 0\n├ totalMemory: 89.48 GB\n├ freeMemory: 83.5 GB\n├ numberOfProcessors: 20\n├ processors: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n├ numberOfDistances: 2\n└ distances: [10, 21]","category":"page"},{"location":"howtos/howto_topology/#Graphical-output","page":"System Topology","title":"Graphical output","text":"","category":"section"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"Currently, LIKWID.jl doesn't feature a native graphical visualization of the CPU topology. However, it provides a small \"wrapper function\" around likwid-topology -g which should give you an output like this:","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"LIKWID.print_cpu_topology()","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"Graphical Topology\n********************************************************************************\nSocket 0:\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| |   0   | |   1   | |   2   | |   3   | |   4   | |   5   | |   6   | |   7   | |   8   | |   9   | |   10  | |   11  | |   12  | |   13  | |   14  | |   15  | |   16  | |   17  | |   18  | |   19  | |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ |\n| |                                                                                                28 MB                                                                                                | |\n| +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\nSocket 1:\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| |   20  | |   21  | |   22  | |   23  | |   24  | |   25  | |   26  | |   27  | |   28  | |   29  | |   30  | |   31  | |   32  | |   33  | |   34  | |   35  | |   36  | |   37  | |   38  | |   39  | |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | | 32 kB | |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |  1 MB | |\n| +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ +-------+ |\n| +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ |\n| |                                                                                                28 MB                                                                                                | |\n| +-----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+ |\n+---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n","category":"page"},{"location":"howtos/howto_topology/#GPU","page":"System Topology","title":"GPU","text":"","category":"section"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"Query GPU topology information:","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"topo = LIKWID.get_gpu_topology()","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"LIKWID.GpuTopology\n├ numDevices: 1\n└ devices: ... (1 elements)","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"gpu = first(topo.devices)","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"LIKWID.GpuDevice\n├ devid: 0\n├ numaNode: 1\n├ name: NVIDIA GeForce RTX 2080 Ti\n├ short_name: nvidia_gpu_cc_ge_7\n├ mem: 10.76 GB\n├ compute_capability_major: 7\n├ compute_capability_minor: 5\n├ maxThreadsPerBlock: 1024\n├ maxThreadsDim: (1024, 1024, 64)\n├ maxGridSize: (2147483647, 65535, 65535)\n├ sharedMemPerBlock: 49152\n├ totalConstantMemory: 65536\n├ simdWidth: 32\n├ memPitch: 2147483647\n├ regsPerBlock: 0\n├ clockRatekHz: 1545000\n├ textureAlign: 512\n├ surfaceAlign: 512\n├ l2Size: 5767168\n├ memClockRatekHz: 7000000\n├ pciBus: 175\n├ pciDev: 0\n├ pciDom: 0\n├ maxBlockRegs: 65536\n├ numMultiProcs: 68\n├ maxThreadPerMultiProc: 1024\n├ memBusWidth: 352\n├ unifiedAddrSpace: true\n├ ecc: false\n├ asyncEngines: 3\n├ mapHostMem: true\n└ integrated: false","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"","category":"page"},{"location":"howtos/howto_topology/","page":"System Topology","title":"System Topology","text":"This page was generated using Literate.jl.","category":"page"},{"location":"references/marker_gpu/#Marker-API-(GPU)","page":"Marker API (GPU)","title":"Marker API (GPU)","text":"","category":"section"},{"location":"references/marker_gpu/","page":"Marker API (GPU)","title":"Marker API (GPU)","text":"Note: This is a maturing feature. Only NVIDIA GPUs are supported.","category":"page"},{"location":"references/marker_gpu/#Index","page":"Marker API (GPU)","title":"Index","text":"","category":"section"},{"location":"references/marker_gpu/","page":"Marker API (GPU)","title":"Marker API (GPU)","text":"Pages   = [\"marker_gpu.md\"]\nOrder   = [:function, :macro, :type]","category":"page"},{"location":"references/marker_gpu/#API","page":"Marker API (GPU)","title":"API","text":"","category":"section"},{"location":"references/marker_gpu/","page":"Marker API (GPU)","title":"Marker API (GPU)","text":"Modules = [LIKWID.GPUMarker]","category":"page"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.close-Tuple{}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.close","text":"Close the connection to the LIKWID GPU Marker API and write out measurement data to file. This file will be evaluated by likwid-perfctr.\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.getregion-Tuple{AbstractString}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.getregion","text":"getregion(regiontag::AbstractString) -> nevents, events, time, count\n\nGet the intermediate results of the region identified by regiontag. On success, it returns     * nevents: the number of events in the current group,     * events: a list with all the aggregated event results,     * time: the measurement time for the region and     * count: the number of calls.\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.gpumarker-Tuple{Any, AbstractString}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.gpumarker","text":"gpumarker(f, regiontag::AbstractString)\n\nAdds a LIKWID GPU marker region around the execution of the given function f using GPUMarker.startregion, GPUMarker.stopregion under the hood. Note that LIKWID.GPUMarker.init() and LIKWID.GPUMarker.close() must be called before and after, respectively.\n\nExamples\n\njulia> using LIKWID, CUDA\n\njulia> GPUMarker.init()\n\njulia> gpumarker(\"sleeping...\") do\n           sleep(1)\n       end\ntrue\n\njulia> gpumarker(()->CUDA.rand(100), \"create rand vec\")\ntrue\n\njulia> GPUMarker.close()\n\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.init-Tuple{}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.init","text":"Initialize the NvMon Marker API of the LIKWID library. Must be called previous to all other functions.\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.isactive-Tuple{}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.isactive","text":"Checks whether the NVIDIA GPU Marker API is active, i.e. julia has been started under likwid-perfctr -G ... -W ... -m.\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.nextgroup-Tuple{}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.nextgroup","text":"Switch to the next event set in a round-robin fashion. If you have set only one event set on the command line, this function performs no operation.\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.registerregion-Tuple{AbstractString}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.registerregion","text":"Register a region with name regiontag to the GPU Marker API. On success, true is returned.\n\nThis is an optional function to reduce the overhead of region registration at Marker.startregion. If you don't call registerregion, the registration is done at startregion.\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.resetregion-Tuple{AbstractString}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.resetregion","text":"Reset the values stored using the region name regiontag. On success, true is returned.\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.startregion-Tuple{AbstractString}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.startregion","text":"Start measurements under the name regiontag. On success, true is returned.\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.stopregion-Tuple{AbstractString}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.stopregion","text":"Stop measurements under the name regiontag. On success, true is returned.\n\n\n\n\n\n","category":"method"},{"location":"references/marker_gpu/#LIKWID.GPUMarker.@gpumarker-Tuple{Any, Any}","page":"Marker API (GPU)","title":"LIKWID.GPUMarker.@gpumarker","text":"Convenience macro for flanking code with GPUMarker.startregion and GPUMarker.stopregion.\n\nExamples\n\njulia> using LIKWID, CUDA\n\njulia> GPUMarker.init()\n\njulia> @gpumarker \"sleeping...\" sleep(1)\ntrue\n\njulia> @gpumarker \"create rand vec\" CUDA.rand(100)\ntrue\n\njulia> GPUMarker.close()\n\n\n\n\n\n\n","category":"macro"},{"location":"references/temperature/#CPU-Temperature","page":"CPU temperature","title":"CPU Temperature","text":"","category":"section"},{"location":"references/temperature/#API","page":"CPU temperature","title":"API","text":"","category":"section"},{"location":"references/temperature/","page":"CPU temperature","title":"CPU temperature","text":"Pages   = [\"temperature.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"references/temperature/#Functions","page":"CPU temperature","title":"Functions","text":"","category":"section"},{"location":"references/temperature/","page":"CPU temperature","title":"CPU temperature","text":"LIKWID.init_thermal\nLIKWID.get_temperature","category":"page"},{"location":"references/temperature/#LIKWID.init_thermal","page":"CPU temperature","title":"LIKWID.init_thermal","text":"Initialize thermal measurements on the given CPU.\n\n\n\n\n\n","category":"function"},{"location":"references/temperature/#LIKWID.get_temperature","page":"CPU temperature","title":"LIKWID.get_temperature","text":"Read the current temperature of the given CPU in degrees Celsius.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#Miscellaneous","page":"Miscellaneous","title":"Miscellaneous","text":"","category":"section"},{"location":"references/misc/#Index","page":"Miscellaneous","title":"Index","text":"","category":"section"},{"location":"references/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"Pages   = [\"misc.md\"]\nOrder   = [:function, :type]","category":"page"},{"location":"references/misc/#API","page":"Miscellaneous","title":"API","text":"","category":"section"},{"location":"references/misc/","page":"Miscellaneous","title":"Miscellaneous","text":"LIKWID.setverbosity\nLIKWID.gpusupport\nLIKWID.pinmask\nLIKWID.accessmode\nLIKWID.env\nLIKWID.clearenv\nLIKWID.LIKWID_FORCE\nLIKWID.LIKWID_NO_ACCESS\nLIKWID.LIKWID_PIN\nLIKWID.LIKWID_SILENT\nLIKWID.LIKWID_SKIP\nLIKWID.LIKWID_DEBUG\nLIKWID.LIKWID_IGNORE_CPUSET\nLIKWID.LIKWID_FILEPATH\nLIKWID.LIKWID_MODE\nLIKWID.LIKWID_EVENTS\nLIKWID.LIKWID_THREADS\nLIKWID.LIKWID_MPI_CONNECT","category":"page"},{"location":"references/misc/#LIKWID.setverbosity","page":"Miscellaneous","title":"LIKWID.setverbosity","text":"Set the verbosity level of the LIKWID library. Returns true on success.\n\nOptions are:\n\nLIKWID.LibLikwid.DEBUGLEV_ONLY_ERROR or 0\nLIKWID.LibLikwid.DEBUGLEV_INFO or 1\nLIKWID.LibLikwid.DEBUGLEV_DETAIL or 2\nLIKWID.LibLikwid.DEBUGLEV_DEVELOP or 3\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.gpusupport","page":"Miscellaneous","title":"LIKWID.gpusupport","text":"Returns whether LIKWID has been compiled with GPU support (i.e. has been compiled with NVIDIA_INTERFACE=true).\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.pinmask","page":"Miscellaneous","title":"LIKWID.pinmask","text":"pinmask(N::Integer) -> mask\n\nGenerates a mask that can be supplied to likwid pin -s <mask> to pin N Julia threads.\n\nTaken from https://discourse.julialang.org/t/thread-affinitization-pinning-julia-threads-to-cores/58069/8.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.accessmode","page":"Miscellaneous","title":"LIKWID.accessmode","text":"Query the access mode used by LIKWID, i.e. either ACCESSMODE_PERF, ACCESSMODE_DAEMON, or ACCESSMODE_DIRECT.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.env","page":"Miscellaneous","title":"LIKWID.env","text":"List the values of LIKWID_* environment variables.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.clearenv","page":"Miscellaneous","title":"LIKWID.clearenv","text":"Unset all LIKWID_* environment variables (for the current session).\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_FORCE","page":"Miscellaneous","title":"LIKWID.LIKWID_FORCE","text":"Enables the overwriting of counters that are detected to be in-use. The environment variable is similar to the -f/--force command line switch for likwid-perfctr.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_NO_ACCESS","page":"Miscellaneous","title":"LIKWID.LIKWID_NO_ACCESS","text":"The execution does not require the access layer (access to hardware counters). For example, this variable is set by likwid-topology or likwid-pin.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_PIN","page":"Miscellaneous","title":"LIKWID.LIKWID_PIN","text":"The comma-separated list contains the CPUs the application threads should be pinned to. Careful, the first CPU in the cpuset must be the last entry because the application is pinned to this CPU per default.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_SILENT","page":"Miscellaneous","title":"LIKWID.LIKWID_SILENT","text":"Disable stdout output caused by the library and the scripts. Some scripts provide the -q/--quiet command line switch which provides the same functionality.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_SKIP","page":"Miscellaneous","title":"LIKWID.LIKWID_SKIP","text":"Variable content must be a hexmask. This hexmask describes which threads should be skipped while pinning. This function is required to avoid pinning the shepherd threads used by some OpenMP and MPI implementations. The version 4.3.1 introduced an automatic detection of the shepherd threads. In most cases the detection works, but if not, the hexmask overwrites the automatic detection.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_DEBUG","page":"Miscellaneous","title":"LIKWID.LIKWID_DEBUG","text":"Verbosity settings for the LIKWID library.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_IGNORE_CPUSET","page":"Miscellaneous","title":"LIKWID.LIKWID_IGNORE_CPUSET","text":"LIKWID respects the CPUset of the calling process. If you want to measure/run outside of this CPUset, use this environment variable. It will not ignore the CPUset but create a new CPUset internally which contains sysconf(_SC_NPROCESSORS_CONF) hardware threads.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_FILEPATH","page":"Miscellaneous","title":"LIKWID.LIKWID_FILEPATH","text":"Filepath for the result file of the MarkerAPI.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_MODE","page":"Miscellaneous","title":"LIKWID.LIKWID_MODE","text":"Access mode for MarkerAPI. 1 is the code for the access daemon.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_EVENTS","page":"Miscellaneous","title":"LIKWID.LIKWID_EVENTS","text":"Event string or performance group name. Multiple event strings or performance group names can be separated by |.\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_THREADS","page":"Miscellaneous","title":"LIKWID.LIKWID_THREADS","text":"The CPUs LIKWID is configured to run on (comma-separated list).\n\n\n\n\n\n","category":"function"},{"location":"references/misc/#LIKWID.LIKWID_MPI_CONNECT","page":"Miscellaneous","title":"LIKWID.LIKWID_MPI_CONNECT","text":"Connection method for Intel MPI. Default is ssh, see option -r of mpdboot or similar.\n\n\n\n\n\n","category":"function"},{"location":"#LIKWID-Like-I-Knew-What-I'm-Doing","page":"LIKWID","title":"LIKWID - Like I Knew What I'm Doing","text":"","category":"section"},{"location":"","page":"LIKWID","title":"LIKWID","text":"LIKWID.jl is a Julia wrapper for the  performance monitoring and benchmarking suite LIKWID. It is an effort by the Paderborn Center for Parallel Computing (PC²) and, originally, the MIT JuliaLab.","category":"page"},{"location":"#Installation","page":"LIKWID","title":"Installation","text":"","category":"section"},{"location":"","page":"LIKWID","title":"LIKWID","text":"Prerequisites:","category":"page"},{"location":"","page":"LIKWID","title":"LIKWID","text":"You must have likwid installed (see the build & install instructions).\nYou must be running Linux. (LIKWID doesn't support macOS or Windows.)","category":"page"},{"location":"","page":"LIKWID","title":"LIKWID","text":"LIKWID.jl is a registered Julia package. Hence, you can simply add it to your Julia environment with the command","category":"page"},{"location":"","page":"LIKWID","title":"LIKWID","text":"] add LIKWID","category":"page"},{"location":"#LIKWID.jl-vs-LinuxPerf.jl","page":"LIKWID","title":"LIKWID.jl vs LinuxPerf.jl","text":"","category":"section"},{"location":"","page":"LIKWID","title":"LIKWID","text":"As per default (and recommendation) LIKWID(.jl) uses a custom access daemon to monitor hardware performance counters. In contrast, LinuxPerf.jl uses Linux's perf_events. However, it is possible to make LIKWID use perf_events as an alternative (inferior) backend. See here for more information.","category":"page"},{"location":"#Supported-CPUs","page":"LIKWID","title":"Supported CPUs","text":"","category":"section"},{"location":"","page":"LIKWID","title":"LIKWID","text":"using LIKWID","category":"page"},{"location":"","page":"LIKWID","title":"LIKWID","text":"LIKWID.print_supported_cpus()\nLibc.flush_cstdio() # hide","category":"page"},{"location":"references/nvmon/#NVIDIA-Monitoring-(NvMon)","page":"NVIDIA monitoring","title":"NVIDIA Monitoring (NvMon)","text":"","category":"section"},{"location":"references/nvmon/","page":"NVIDIA monitoring","title":"NVIDIA monitoring","text":"Note: This is a maturing feature. Only NVIDIA GPUs are supported.","category":"page"},{"location":"references/nvmon/#Index","page":"NVIDIA monitoring","title":"Index","text":"","category":"section"},{"location":"references/nvmon/","page":"NVIDIA monitoring","title":"NVIDIA monitoring","text":"Pages   = [\"nvmon.md\"]\nOrder   = [:function, :macro, :type]","category":"page"},{"location":"references/nvmon/#API","page":"NVIDIA monitoring","title":"API","text":"","category":"section"},{"location":"references/nvmon/","page":"NVIDIA monitoring","title":"NVIDIA monitoring","text":"Modules = [LIKWID.NvMon]","category":"page"},{"location":"references/nvmon/#LIKWID.NvMon.add_event_set-Tuple{AbstractString}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.add_event_set","text":"add_event_set(estr) -> groupid\n\nAdd a performance group or a custom event set to the nvmon module. Returns a groupid (starting at 1) which is required to later specify the event set.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_event_results-Tuple{Any, Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_event_results","text":"get_event_results([groupid_or_groupname, eventid_or_eventname, gpuid::Integer])\n\nRetrieve the results of monitored events. Same as get_metric_results but for raw events.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_id_of_active_group-Tuple{}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_id_of_active_group","text":"Return the groupid of the currently activate group.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_last_metric-Tuple{Integer, Integer, Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_last_metric","text":"Return the derived metric result of the last measurement cycle identified by group groupid and the indices for metric metricidx and gpu gpuid (all starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_last_result-Tuple{Integer, Integer, Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_last_result","text":"Return the raw counter register result of the last measurement cycle identified by group groupid and the indices for event eventidx and gpu gpuid (all starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_longinfo_of_group-Tuple{Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_longinfo_of_group","text":"Return the (long) description of a performance group with id groupid (starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_metric-Tuple{Integer, Integer, Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_metric","text":"Return the derived metric result of all measurements identified by group groupid and the indices for metric metricidx and gpu gpuid (all starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_metric_results-Tuple{Any, Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_metric_results","text":"get_metric_results([groupid_or_groupname, metricid_or_metricname, gpuid::Integer])\n\nRetrieve the results of monitored metrics.\n\nOptionally, a group, metric, and gpuid can be provided to select a subset of metrics or a single metric. If given as integers, note that groupid, metricid, and gpuid all start at 1 and the latter enumerates the monitored gpus.\n\nIf no arguments are provided, a nested data structure is returned in which different levels correspond to performance groups, gpus, and metrics (in this order). ```\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_metric_results-Tuple{}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_metric_results","text":"get_metric_results()\n\nGet the metric results for all performance groups and all monitored (NvMon.init) gpus.\n\nReturns a an OrderedDict whose keys correspond to the performance groups and the values hold the results for all monitored gpus. ```\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_name_of_counter-Tuple{Integer, Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_name_of_counter","text":"Return the name of the counter register identified by groupid and eventidx (both start at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_name_of_event-Tuple{Integer, Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_name_of_event","text":"Return the name of the event identified by groupid and eventidx (both start at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_name_of_group-Tuple{Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_name_of_group","text":"Return the name of the group identified by groupid (starts at 1). If it is a custom event set, the name is set to Custom.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_name_of_metric-Tuple{Integer, Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_name_of_metric","text":"Return the name of a derived metric identified by groupid and metricidx (both start at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_number_of_events-Tuple{Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_number_of_events","text":"Return the number of events in the group with id groupid (starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_number_of_gpus-Tuple{}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_number_of_gpus","text":"Return the number of GPUs initialized in the nvmon module.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_number_of_groups-Tuple{}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_number_of_groups","text":"Return the number of groups currently registered in the nvmon module.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_number_of_metrics-Tuple{Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_number_of_metrics","text":"Return the number of metrics in the group with id groupid (starts at 1). Always zero for custom event sets.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_result-Tuple{Integer, Integer, Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_result","text":"Return the raw counter register result of all measurements identified by group groupid and the indices for event eventidx and gpu gpuid (all starting at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_shortinfo_of_group-Tuple{Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_shortinfo_of_group","text":"Return the short information about a performance group with id groupid (starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.get_time_of_group-Tuple{Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.get_time_of_group","text":"Return the measurement time for group identified by groupid (starts at 1).\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.init","page":"NVIDIA monitoring","title":"LIKWID.NvMon.init","text":"init(gpuid_or_gpuids)\n\nInitialize LIKWID's NvMon module for the gpu(s) with the given gpu id(s) (starting at 0!).\n\n\n\n\n\n","category":"function"},{"location":"references/nvmon/#LIKWID.NvMon.isgroupsupported","page":"NVIDIA monitoring","title":"LIKWID.NvMon.isgroupsupported","text":"Checks if the given performance group is available on the given GPU (defaults to the first).\n\n\n\n\n\n","category":"function"},{"location":"references/nvmon/#LIKWID.NvMon.nvmon-Tuple{Any, Any}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.nvmon","text":"nvmon(f, group_or_groups[; gpuids])\n\nMonitor performance groups while executing the given function f on one or multiple GPUs. Note that\n\nNvMon.init and NvMon.finalize are called automatically\nthe measurement of multiple performance groups is sequential and requires multiple executions of f!\n\nKeyword arguments:\n\ngpuids (default: first GPU): specify the GPUs to be monitored\n\nNote: This is an experimental feature and might change or be dropped any time!\n\nExample\n\njulia> using LIKWID\n\njulia> x = CUDA.rand(1000); y = CUDA.rand(1000);\n\njulia> metrics, events = nvmon(\"FLOPS_DP\") do\n           CUDA.@sync x .+ y;\n       end;\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.read_counters-Tuple{}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.read_counters","text":"Read the counter registers. To be executed after start_counters and before stop_counters. Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.setup_counters-Tuple{Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.setup_counters","text":"Program the counter registers to measure all events in group groupid (starts at 1). Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.start_counters-Tuple{}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.start_counters","text":"Start the counter registers. Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.stop_counters-Tuple{}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.stop_counters","text":"Stop the counter registers. Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.supported_groups","page":"NVIDIA monitoring","title":"LIKWID.NvMon.supported_groups","text":"Return a dictionary of all available nvmon groups for the GPU identified by gpu (starts at 0).\n\nExamples\n\njulia> NvMon.supported_groups()\nDict{String, LIKWID.GroupInfoCompact} with 4 entries:\n  \"DATA\"     => DATA => Load to store ratio\n  \"FLOPS_SP\" => FLOPS_SP => Single-precision floating point\n  \"FLOPS_HP\" => FLOPS_HP => Half-precision floating point\n  \"FLOPS_DP\" => FLOPS_DP => Double-precision floating point\n\n\n\n\n\n","category":"function"},{"location":"references/nvmon/#LIKWID.NvMon.switch_group-Tuple{Integer}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.switch_group","text":"Switch currently active group to groupid (starts at 1). Returns true on success.\n\n\n\n\n\n","category":"method"},{"location":"references/nvmon/#LIKWID.NvMon.@nvmon-Tuple{Any, Any}","page":"NVIDIA monitoring","title":"LIKWID.NvMon.@nvmon","text":"@nvmon group_or_groups codeblock\n\nSee also: nvmon\n\nNote: This is an experimental feature and might change or be dropped any time!\n\nExample\n\njulia> using LIKWID\n\njulia> x = CUDA.rand(1000); y = CUDA.rand(1000);\n\njulia> metrics, events = @nvmon \"FLOPS_DP\" x .+ y;\n\n\n\n\n\n","category":"macro"}]
}
